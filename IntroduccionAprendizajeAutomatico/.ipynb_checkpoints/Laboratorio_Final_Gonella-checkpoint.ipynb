{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio Final: \n",
    "### Alumno: Martín Gonella\n",
    "## \"Armado de un esquema de aprendizaje automático\"\n",
    "\n",
    "En el laboratorio final se espera que puedan poner en práctica los conocimientos adquiridos en el curso, trabajando con un conjunto de datos de clasificación.\n",
    "\n",
    "El objetivo es que se introduzcan en el desarrollo de un esquema para hacer tareas de aprendizaje automático: selección de un modelo, ajuste de hiperparámetros y evaluación.\n",
    "\n",
    "El conjunto de datos a utilizar está en `./data/loan_data.csv`. Si abren el archivo verán que al principio (las líneas que empiezan con `#`) describen el conjunto de datos y sus atributos (incluyendo el atributo de etiqueta o clase).\n",
    "\n",
    "Se espera que hagan uso de las herramientas vistas en el curso. Se espera que hagan uso especialmente de las herramientas brindadas por `scikit-learn`.\n",
    "\n",
    "---\n",
    "## Librerías y semilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'plot_learning_curve'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-51d57ed23040>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mListedColormap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_boundary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_learning_curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRidge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'plot_learning_curve'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from ml.visualization import plot_confusion_matrix, classifier_boundary, plot_learning_curve\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Perceptron, Ridge\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "np.random.seed(0)  #Para mayor determinismo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Carga de datos\n",
    "\n",
    "La celda siguiente se encarga de la carga de datos (haciendo uso de pandas). Estos serán los que se trabajarán en el resto del laboratorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./data/loan_data.csv\", comment=\"#\")\n",
    "#display(dataset.head(10))\n",
    "print('\\nLongitud del dataset: '+str(len(dataset))+'\\n')\n",
    "\n",
    "#División entre instancias y etiquetas\n",
    "X, y = dataset.drop(columns=['TARGET']), dataset.TARGET\n",
    "\n",
    "print('Dataset:')\n",
    "display(X.head(10))\n",
    "\n",
    "print('Target:')\n",
    "display(y.head(10))\n",
    "\n",
    "print('Frecuencias del Target')\n",
    "display(dataset.TARGET.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar el problema de aprendizaje autómatico del corriente laboratorio, entra dentro del problema de `clasificación binaria`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Ejercicio 1: División de datos en conjuntos de entrenamiento y evaluación\n",
    "\n",
    "La primer tarea consiste en dividir el conjunto de datos cargados en el apartado anterior en conjuntos de entrenamiento (o *training*) y evaluación (o *test*).\n",
    "\n",
    "El primero será utilizado para la creación/selección del modelo de clasificación. El segundo se utilizará sólo al final (una vez elegidos los mejores hiperparámetros) para ver cuál es el resultado final del modelo sobre un conjunto de datos independiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos aproximadamente 80% de los datos para entrenamiento y 20% para validación\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# Necesario para poder hacer un regresor por feature\n",
    "feature_map = {feature: idx for idx, feature in enumerate(['LOAN', 'MORTDUE','VALUE','YOJ','DEROG','DELINQ', \n",
    "                                                           'CLAGE','NINQ','CLNO', 'DEBTINC'])}\n",
    "print(\"Listado de atributos\\n====================\")\n",
    "for feature in feature_map:\n",
    "    print(\"- %s\" % feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Ejercicio 2: Elección de un modelo\n",
    "\n",
    "Basándose en lo visto en el teórico escojan y justifiquen un modelo de aprendizaje automático. Recuerden que los pasos para elegir un modelo son:\n",
    "\n",
    "### Selección de hipótesis\n",
    "\n",
    "Regresión logística:\n",
    "\n",
    "$$h_w(x)= \\frac{1}{1+\\exp(-w^T x))}$$\n",
    "\n",
    "### Selección de regularizador\n",
    "\n",
    "A determinar entre Regularizador `L1` y `L2`.\n",
    "\n",
    "### Selección de función de coste\n",
    "\n",
    "$$L(w)=- \\sum_{i=1}^N y_i \\log (h_w(x_i)) + (1-y_i) \\log (1-h_w(x_i))$$\n",
    "\n",
    "### Justificación de las selecciones\n",
    "\n",
    "Como se trata de una `clasificación binaria`, se escoge una regresión logística ya que la salida toma valores de 0 y/o 1. Además, la regresión es de atributos regulares, se escogió esta característica para poder tener un modelo lo más sencillo posible, ya que se piensa utilizar todos los `features` del dataset. En cuanto al regularizador, se escogerá entre `L1` y `L2` dependiendo de cual de ellas brinda mejores resultados.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Selección de hiperparámetros\n",
    "\n",
    "Utilizando búsqueda exhaustiva (*grid search*) con *5-fold cross-validation* y utilizando como métrica el área bajo la curva de ROC (o *ROC-AUC*), hagan una selección de los mejores hiperparámetros para su conjunto de datos y el modelo que hayan elegido en el apartado anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Búsqueda de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "  \n",
    "for idx, penalty in enumerate(('l1', 'l2'), start=1):\n",
    "    exploring_params = {\n",
    "        'C': [1./40., 1./30., 1./20., 1./10., 1./1., 1./0.9, 1./0.8, 1./0.5, 1./0.1, 1./0.01],  # Tasa de regularización\n",
    "        'tol': [1e-3, 1e-5], \n",
    "        'max_iter': [10000, 15000, 20000]\n",
    "    }    \n",
    "    \n",
    "    m = LogisticRegression(penalty=penalty)\n",
    "    model = GridSearchCV(m, exploring_params, cv=5, scoring='roc_auc')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"####################################################################\")\n",
    "    print(\"    Exploración de hiperparámetros para función de coste \\\"%s\\\"    \" % penalty, end=\"\\n\")\n",
    "    print(\"####################################################################\\n\")\n",
    "    \n",
    "    print(\"Mejor conjunto de parámetros:\")\n",
    "    print(model.best_params_, end=\"\\n\\n\")\n",
    "\n",
    "    print(\"Puntajes de la grilla:\", end=\"\\n\")\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "        print(\"Exactitud: %0.3f (+/-%0.03f) para los parámetros %r\" % (mean, std ** 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\", end=\"\\n\")\n",
    "    y_true, y_pred = y_test, model.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred), end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"==================================================================================\", end=\"\\n\\n\")\n",
    "\n",
    "    plt.subplot(1, 2, idx)\n",
    "    plot_confusion_matrix(confusion_matrix(y_true, y_pred),\n",
    "                          classes=[0,1], title=\"Matriz de confusión para %s\" % penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Ejercicio 4: Métricas sobre el conjunto de evaluación\n",
    "\n",
    "Una vez encontrados los mejores hiperparámetros para el modelo seleccionado en los apartados anteriores se evalúa el modelo final entrenado sobre el conjunto de datos de evaluación seleccionado en el ejercicio 1. Pueden utilizar las métricas que crean convenientes. Es mejor utilizar más de una métrica. Particularmente el *reporte de clasificación* y la *matriz de confusión* son buenos ejemplos de métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros determinados en el punto anterior:\n",
    "penalty = 'l1'  \n",
    "C = 1./0.9      \n",
    "max_iter = 20000\n",
    "tol = 0.001   \n",
    "\n",
    "model = LogisticRegression(penalty=penalty, C=C, max_iter=max_iter, tol=tol)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluamos el desempeño del clasificador utilizando la exactitud (accuracy) sobre el conjunto\n",
    "# de datos de entrenamiento (X_train, y_train) y lo comparamos con el de validación (X_val, y_val)\n",
    "# La exactitud toma valor en el rango [0, 1] donde más alto es mejor\n",
    "print('Exactitud para entrenamiento: %.2f' %  accuracy_score(y_train, model.predict(X_train)))\n",
    "print('Exactitud para validación: %.2f' % accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plot_confusion_matrix(confusion_matrix(y_train, model.predict(X_train)),\n",
    "                classes=[0,1],title='Matriz de confusión para entrenamiento (sin normalizar)')\n",
    "plt.subplot(2, 2, 3)\n",
    "plot_confusion_matrix(confusion_matrix(y_train, model.predict(X_train)),\n",
    "                classes=[0,1],normalize=True,title='Matriz de confusión para entrenamiento (normalizando)')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plot_confusion_matrix(confusion_matrix(y_test, model.predict(X_test)),\n",
    "                classes=[0,1],title='Matriz de confusión para validación (sin normalizar)')\n",
    "plt.subplot(2, 2, 4)\n",
    "plot_confusion_matrix(confusion_matrix(y_test, model.predict(X_test)),\n",
    "                classes=[0,1], normalize=True,title='Matriz de confusión para validación (normalizando)')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Ejercicio 5 (opcional): Curvas de ROC\n",
    "\n",
    "Como ejercicio adicional (opcional), pueden redefinir el umbral de decisión óptimo del problema a partir de los resultados que muestren curvas de ROC como justificación. \n",
    "\n",
    "Pueden ver esto mediante la [graficación de las curvas de ROC](http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html). En el link que se les brinda se muestra como hacer para graficar curvas de ROC para problemas multiclase. Sin embargo se puede adaptar fácilmente a un problema binario obviando la parte donde se calcula la curva clase por clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_true, y_pred = y_test, model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_pred, pos_label=1)\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
