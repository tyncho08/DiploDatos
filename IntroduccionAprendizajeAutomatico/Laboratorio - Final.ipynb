{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio Final: \n",
    "### Alumno: Martín Gonella\n",
    "## \"Armado de un esquema de aprendizaje automático\"\n",
    "\n",
    "En el laboratorio final se espera que puedan poner en práctica los conocimientos adquiridos en el curso, trabajando con un conjunto de datos de clasificación.\n",
    "\n",
    "El objetivo es que se introduzcan en el desarrollo de un esquema para hacer tareas de aprendizaje automático: selección de un modelo, ajuste de hiperparámetros y evaluación.\n",
    "\n",
    "El conjunto de datos a utilizar está en `./data/loan_data.csv`. Si abren el archivo verán que al principio (las líneas que empiezan con `#`) describen el conjunto de datos y sus atributos (incluyendo el atributo de etiqueta o clase).\n",
    "\n",
    "Se espera que hagan uso de las herramientas vistas en el curso. Se espera que hagan uso especialmente de las herramientas brindadas por `scikit-learn`.\n",
    "\n",
    "---\n",
    "## Librerías y semilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from ml.visualization import plot_confusion_matrix, classifier_boundary, plot_learning_curve\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Perceptron, Ridge\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "np.random.seed(0)  #Para mayor determinismo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Carga de datos\n",
    "\n",
    "La celda siguiente se encarga de la carga de datos (haciendo uso de pandas). Estos serán los que se trabajarán en el resto del laboratorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Longitud del dataset: 1854\n",
      "\n",
      "Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOAN</th>\n",
       "      <th>MORTDUE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>YOJ</th>\n",
       "      <th>DEROG</th>\n",
       "      <th>DELINQ</th>\n",
       "      <th>CLAGE</th>\n",
       "      <th>NINQ</th>\n",
       "      <th>CLNO</th>\n",
       "      <th>DEBTINC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4700</td>\n",
       "      <td>88026.0</td>\n",
       "      <td>115506.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.248332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>29.209023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19300</td>\n",
       "      <td>39926.0</td>\n",
       "      <td>101208.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.051638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.545694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5700</td>\n",
       "      <td>71556.0</td>\n",
       "      <td>79538.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.643085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>41.210012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13000</td>\n",
       "      <td>44875.0</td>\n",
       "      <td>57713.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184.990324</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.602076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19300</td>\n",
       "      <td>72752.0</td>\n",
       "      <td>106084.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193.707100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.686106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11500</td>\n",
       "      <td>53651.0</td>\n",
       "      <td>87547.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191.396887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>34.368651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17200</td>\n",
       "      <td>103519.0</td>\n",
       "      <td>118074.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.678612</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>41.418353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24200</td>\n",
       "      <td>22763.0</td>\n",
       "      <td>47622.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.922691</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.040945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12600</td>\n",
       "      <td>62493.0</td>\n",
       "      <td>77141.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>266.333101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.007872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12300</td>\n",
       "      <td>90006.0</td>\n",
       "      <td>121122.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.497541</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.910482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LOAN   MORTDUE     VALUE   YOJ  DEROG  DELINQ       CLAGE  NINQ  CLNO  \\\n",
       "0   4700   88026.0  115506.0   6.0    0.0     0.0  182.248332   0.0  27.0   \n",
       "1  19300   39926.0  101208.0   4.0    0.0     0.0  140.051638   0.0  14.0   \n",
       "2   5700   71556.0   79538.0   2.0    0.0     0.0   92.643085   0.0  15.0   \n",
       "3  13000   44875.0   57713.0   0.0    1.0     0.0  184.990324   1.0  12.0   \n",
       "4  19300   72752.0  106084.0  11.0    0.0     0.0  193.707100   1.0  13.0   \n",
       "5  11500   53651.0   87547.0  18.0    0.0     0.0  191.396887   0.0  16.0   \n",
       "6  17200  103519.0  118074.0   0.0    0.0     0.0  102.678612   1.0  21.0   \n",
       "7  24200   22763.0   47622.0  23.0    0.0     0.0  126.922691   1.0  10.0   \n",
       "8  12600   62493.0   77141.0  13.0    0.0     0.0  266.333101   0.0  26.0   \n",
       "9  12300   90006.0  121122.0   9.0    0.0     0.0  133.497541   1.0  21.0   \n",
       "\n",
       "     DEBTINC  \n",
       "0  29.209023  \n",
       "1  31.545694  \n",
       "2  41.210012  \n",
       "3  28.602076  \n",
       "4  30.686106  \n",
       "5  34.368651  \n",
       "6  41.418353  \n",
       "7  23.040945  \n",
       "8  27.007872  \n",
       "9  36.910482  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    0\n",
       "9    0\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frecuencias del Target\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1545\n",
       "1     309\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"./data/loan_data.csv\", comment=\"#\")\n",
    "#display(dataset.head(10))\n",
    "print('\\nLongitud del dataset: '+str(len(dataset))+'\\n')\n",
    "\n",
    "#División entre instancias y etiquetas\n",
    "X, y = dataset.drop(columns=['TARGET']), dataset.TARGET\n",
    "\n",
    "print('Dataset:')\n",
    "display(X.head(10))\n",
    "\n",
    "print('Target:')\n",
    "display(y.head(10))\n",
    "\n",
    "print('Frecuencias del Target')\n",
    "display(dataset.TARGET.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar el problema de aprendizaje autómatico del corriente laboratorio, entra dentro del problema de `clasificación binaria`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Ejercicio 1: División de datos en conjuntos de entrenamiento y evaluación\n",
    "\n",
    "La primer tarea consiste en dividir el conjunto de datos cargados en el apartado anterior en conjuntos de entrenamiento (o *training*) y evaluación (o *test*).\n",
    "\n",
    "El primero será utilizado para la creación/selección del modelo de clasificación. El segundo se utilizará sólo al final (una vez elegidos los mejores hiperparámetros) para ver cuál es el resultado final del modelo sobre un conjunto de datos independiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listado de atributos\n",
      "====================\n",
      "- LOAN\n",
      "- MORTDUE\n",
      "- VALUE\n",
      "- YOJ\n",
      "- DEROG\n",
      "- DELINQ\n",
      "- CLAGE\n",
      "- NINQ\n",
      "- CLNO\n",
      "- DEBTINC\n"
     ]
    }
   ],
   "source": [
    "# Utilizamos aproximadamente 80% de los datos para entrenamiento y 20% para validación\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# Necesario para poder hacer un regresor por feature\n",
    "feature_map = {feature: idx for idx, feature in enumerate(['LOAN', 'MORTDUE','VALUE','YOJ','DEROG','DELINQ', \n",
    "                                                           'CLAGE','NINQ','CLNO', 'DEBTINC'])}\n",
    "print(\"Listado de atributos\\n====================\")\n",
    "for feature in feature_map:\n",
    "    print(\"- %s\" % feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Ejercicio 2: Elección de un modelo\n",
    "\n",
    "Basándose en lo visto en el teórico escojan y justifiquen un modelo de aprendizaje automático. Recuerden que los pasos para elegir un modelo son:\n",
    "\n",
    "### Selección de hipótesis\n",
    "\n",
    "Regresión logística.\n",
    "\n",
    "### Selección de regularizador\n",
    "\n",
    "Atributos regulares.\n",
    "\n",
    "### Selección de función de coste\n",
    "\n",
    "A determinar entre Regularizador L1 y L2.\n",
    "\n",
    "### Justificación de las selecciones\n",
    "\n",
    "Como se trata de una `clasificación binaria`, se escoge una regresión logística ya que la salida toma valores de 0 y/o 1. Además, la regresión es de atributos regulares, se escogió esta característica para poder tener un modelo lo más sencillo posible, ya que se piensa utilizar todos los `features` del dataset. En cuanto a la función de penalidad se escogerá entre `L1` y `L2` dependiendo de cual de ellas brinda mejores resultados.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Selección de hiperparámetros\n",
    "\n",
    "Utilizando búsqueda exhaustiva (*grid search*) con *5-fold cross-validation* y utilizando como métrica el área bajo la curva de ROC (o *ROC-AUC*), hagan una selección de los mejores hiperparámetros para su conjunto de datos y el modelo que hayan elegido en el apartado anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Búsqueda de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################\n",
      "    Exploración de hiperparámetros para función de coste \"l1\"    \n",
      "####################################################################\n",
      "\n",
      "Mejor conjunto de parámetros:\n",
      "{'C': 1.1111111111111112, 'max_iter': 20000, 'tol': 0.001}\n",
      "\n",
      "Puntajes de la grilla:\n",
      "Exactitud: 0.758 (+/-0.002) para los parámetros {'C': 0.025, 'max_iter': 10000, 'tol': 0.001}\n",
      "Exactitud: 0.758 (+/-0.002) para los parámetros {'C': 0.025, 'max_iter': 10000, 'tol': 1e-05}\n",
      "Exactitud: 0.758 (+/-0.002) para los parámetros {'C': 0.025, 'max_iter': 15000, 'tol': 0.001}\n",
      "Exactitud: 0.758 (+/-0.002) para los parámetros {'C': 0.025, 'max_iter': 15000, 'tol': 1e-05}\n",
      "Exactitud: 0.758 (+/-0.002) para los parámetros {'C': 0.025, 'max_iter': 20000, 'tol': 0.001}\n",
      "Exactitud: 0.758 (+/-0.002) para los parámetros {'C': 0.025, 'max_iter': 20000, 'tol': 1e-05}\n",
      "Exactitud: 0.764 (+/-0.002) para los parámetros {'C': 0.03333333333333333, 'max_iter': 10000, 'tol': 0.001}\n",
      "Exactitud: 0.763 (+/-0.002) para los parámetros {'C': 0.03333333333333333, 'max_iter': 10000, 'tol': 1e-05}\n",
      "Exactitud: 0.764 (+/-0.002) para los parámetros {'C': 0.03333333333333333, 'max_iter': 15000, 'tol': 0.001}\n",
      "Exactitud: 0.763 (+/-0.002) para los parámetros {'C': 0.03333333333333333, 'max_iter': 15000, 'tol': 1e-05}\n",
      "Exactitud: 0.764 (+/-0.002) para los parámetros {'C': 0.03333333333333333, 'max_iter': 20000, 'tol': 0.001}\n",
      "Exactitud: 0.763 (+/-0.002) para los parámetros {'C': 0.03333333333333333, 'max_iter': 20000, 'tol': 1e-05}\n",
      "Exactitud: 0.769 (+/-0.002) para los parámetros {'C': 0.05, 'max_iter': 10000, 'tol': 0.001}\n",
      "Exactitud: 0.769 (+/-0.002) para los parámetros {'C': 0.05, 'max_iter': 10000, 'tol': 1e-05}\n",
      "Exactitud: 0.770 (+/-0.002) para los parámetros {'C': 0.05, 'max_iter': 15000, 'tol': 0.001}\n",
      "Exactitud: 0.769 (+/-0.002) para los parámetros {'C': 0.05, 'max_iter': 15000, 'tol': 1e-05}\n",
      "Exactitud: 0.770 (+/-0.002) para los parámetros {'C': 0.05, 'max_iter': 20000, 'tol': 0.001}\n",
      "Exactitud: 0.769 (+/-0.002) para los parámetros {'C': 0.05, 'max_iter': 20000, 'tol': 1e-05}\n",
      "Exactitud: 0.790 (+/-0.002) para los parámetros {'C': 0.1, 'max_iter': 10000, 'tol': 0.001}\n",
      "Exactitud: 0.791 (+/-0.002) para los parámetros {'C': 0.1, 'max_iter': 10000, 'tol': 1e-05}\n",
      "Exactitud: 0.791 (+/-0.002) para los parámetros {'C': 0.1, 'max_iter': 15000, 'tol': 0.001}\n",
      "Exactitud: 0.791 (+/-0.002) para los parámetros {'C': 0.1, 'max_iter': 15000, 'tol': 1e-05}\n",
      "Exactitud: 0.790 (+/-0.002) para los parámetros {'C': 0.1, 'max_iter': 20000, 'tol': 0.001}\n",
      "Exactitud: 0.791 (+/-0.002) para los parámetros {'C': 0.1, 'max_iter': 20000, 'tol': 1e-05}\n",
      "Exactitud: 0.790 (+/-0.002) para los parámetros {'C': 1.0, 'max_iter': 10000, 'tol': 0.001}\n",
      "Exactitud: 0.790 (+/-0.002) para los parámetros {'C': 1.0, 'max_iter': 10000, 'tol': 1e-05}\n",
      "Exactitud: 0.791 (+/-0.002) para los parámetros {'C': 1.0, 'max_iter': 15000, 'tol': 0.001}\n",
      "Exactitud: 0.790 (+/-0.002) para los parámetros {'C': 1.0, 'max_iter': 15000, 'tol': 1e-05}\n",
      "Exactitud: 0.791 (+/-0.001) para los parámetros {'C': 1.0, 'max_iter': 20000, 'tol': 0.001}\n",
      "Exactitud: 0.790 (+/-0.002) para los parámetros {'C': 1.0, 'max_iter': 20000, 'tol': 1e-05}\n",
      "Exactitud: 0.790 (+/-0.002) para los parámetros {'C': 1.1111111111111112, 'max_iter': 10000, 'tol': 0.001}\n",
      "Exactitud: 0.790 (+/-0.002) para los parámetros {'C': 1.1111111111111112, 'max_iter': 10000, 'tol': 1e-05}\n",
      "Exactitud: 0.790 (+/-0.002) para los parámetros {'C': 1.1111111111111112, 'max_iter': 15000, 'tol': 0.001}\n",
      "Exactitud: 0.790 (+/-0.002) para los parámetros {'C': 1.1111111111111112, 'max_iter': 15000, 'tol': 1e-05}\n",
      "Exactitud: 0.793 (+/-0.001) para los parámetros {'C': 1.1111111111111112, 'max_iter': 20000, 'tol': 0.001}\n",
      "Exactitud: 0.790 (+/-0.002) para los parámetros {'C': 1.1111111111111112, 'max_iter': 20000, 'tol': 1e-05}\n",
      "Exactitud: 0.790 (+/-0.002) para los parámetros {'C': 1.25, 'max_iter': 10000, 'tol': 0.001}\n",
      "Exactitud: 0.790 (+/-0.002) para los parámetros {'C': 1.25, 'max_iter': 10000, 'tol': 1e-05}\n",
      "Exactitud: 0.791 (+/-0.001) para los parámetros {'C': 1.25, 'max_iter': 15000, 'tol': 0.001}\n",
      "Exactitud: 0.790 (+/-0.002) para los parámetros {'C': 1.25, 'max_iter': 15000, 'tol': 1e-05}\n",
      "Exactitud: 0.791 (+/-0.002) para los parámetros {'C': 1.25, 'max_iter': 20000, 'tol': 0.001}\n",
      "Exactitud: 0.790 (+/-0.002) para los parámetros {'C': 1.25, 'max_iter': 20000, 'tol': 1e-05}\n",
      "Exactitud: 0.790 (+/-0.001) para los parámetros {'C': 2.0, 'max_iter': 10000, 'tol': 0.001}\n",
      "Exactitud: 0.789 (+/-0.002) para los parámetros {'C': 2.0, 'max_iter': 10000, 'tol': 1e-05}\n",
      "Exactitud: 0.791 (+/-0.001) para los parámetros {'C': 2.0, 'max_iter': 15000, 'tol': 0.001}\n",
      "Exactitud: 0.789 (+/-0.002) para los parámetros {'C': 2.0, 'max_iter': 15000, 'tol': 1e-05}\n",
      "Exactitud: 0.791 (+/-0.002) para los parámetros {'C': 2.0, 'max_iter': 20000, 'tol': 0.001}\n",
      "Exactitud: 0.789 (+/-0.002) para los parámetros {'C': 2.0, 'max_iter': 20000, 'tol': 1e-05}\n",
      "Exactitud: 0.790 (+/-0.002) para los parámetros {'C': 10.0, 'max_iter': 10000, 'tol': 0.001}\n",
      "Exactitud: 0.789 (+/-0.001) para los parámetros {'C': 10.0, 'max_iter': 10000, 'tol': 1e-05}\n",
      "Exactitud: 0.790 (+/-0.001) para los parámetros {'C': 10.0, 'max_iter': 15000, 'tol': 0.001}\n",
      "Exactitud: 0.789 (+/-0.001) para los parámetros {'C': 10.0, 'max_iter': 15000, 'tol': 1e-05}\n",
      "Exactitud: 0.789 (+/-0.001) para los parámetros {'C': 10.0, 'max_iter': 20000, 'tol': 0.001}\n",
      "Exactitud: 0.789 (+/-0.001) para los parámetros {'C': 10.0, 'max_iter': 20000, 'tol': 1e-05}\n",
      "Exactitud: 0.789 (+/-0.001) para los parámetros {'C': 100.0, 'max_iter': 10000, 'tol': 0.001}\n",
      "Exactitud: 0.789 (+/-0.001) para los parámetros {'C': 100.0, 'max_iter': 10000, 'tol': 1e-05}\n",
      "Exactitud: 0.790 (+/-0.001) para los parámetros {'C': 100.0, 'max_iter': 15000, 'tol': 0.001}\n",
      "Exactitud: 0.789 (+/-0.001) para los parámetros {'C': 100.0, 'max_iter': 15000, 'tol': 1e-05}\n",
      "Exactitud: 0.790 (+/-0.002) para los parámetros {'C': 100.0, 'max_iter': 20000, 'tol': 0.001}\n",
      "Exactitud: 0.789 (+/-0.001) para los parámetros {'C': 100.0, 'max_iter': 20000, 'tol': 1e-05}\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       313\n",
      "          1       0.77      0.29      0.42        58\n",
      "\n",
      "avg / total       0.87      0.88      0.85       371\n",
      "\n",
      "\n",
      "============================================================================================================\n",
      "\n",
      "####################################################################\n",
      "    Exploración de hiperparámetros para función de coste \"l2\"    \n",
      "####################################################################\n",
      "\n",
      "Mejor conjunto de parámetros:\n",
      "{'C': 1.0, 'max_iter': 10000, 'tol': 1e-05}\n",
      "\n",
      "Puntajes de la grilla:\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 0.025, 'max_iter': 10000, 'tol': 0.001}\n",
      "Exactitud: 0.769 (+/-0.002) para los parámetros {'C': 0.025, 'max_iter': 10000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 0.025, 'max_iter': 15000, 'tol': 0.001}\n",
      "Exactitud: 0.769 (+/-0.002) para los parámetros {'C': 0.025, 'max_iter': 15000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 0.025, 'max_iter': 20000, 'tol': 0.001}\n",
      "Exactitud: 0.769 (+/-0.002) para los parámetros {'C': 0.025, 'max_iter': 20000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 0.03333333333333333, 'max_iter': 10000, 'tol': 0.001}\n",
      "Exactitud: 0.772 (+/-0.002) para los parámetros {'C': 0.03333333333333333, 'max_iter': 10000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 0.03333333333333333, 'max_iter': 15000, 'tol': 0.001}\n",
      "Exactitud: 0.772 (+/-0.002) para los parámetros {'C': 0.03333333333333333, 'max_iter': 15000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 0.03333333333333333, 'max_iter': 20000, 'tol': 0.001}\n",
      "Exactitud: 0.772 (+/-0.002) para los parámetros {'C': 0.03333333333333333, 'max_iter': 20000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 0.05, 'max_iter': 10000, 'tol': 0.001}\n",
      "Exactitud: 0.774 (+/-0.001) para los parámetros {'C': 0.05, 'max_iter': 10000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 0.05, 'max_iter': 15000, 'tol': 0.001}\n",
      "Exactitud: 0.774 (+/-0.001) para los parámetros {'C': 0.05, 'max_iter': 15000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 0.05, 'max_iter': 20000, 'tol': 0.001}\n",
      "Exactitud: 0.774 (+/-0.001) para los parámetros {'C': 0.05, 'max_iter': 20000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 0.1, 'max_iter': 10000, 'tol': 0.001}\n",
      "Exactitud: 0.780 (+/-0.001) para los parámetros {'C': 0.1, 'max_iter': 10000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 0.1, 'max_iter': 15000, 'tol': 0.001}\n",
      "Exactitud: 0.780 (+/-0.001) para los parámetros {'C': 0.1, 'max_iter': 15000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 0.1, 'max_iter': 20000, 'tol': 0.001}\n",
      "Exactitud: 0.780 (+/-0.001) para los parámetros {'C': 0.1, 'max_iter': 20000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 1.0, 'max_iter': 10000, 'tol': 0.001}\n",
      "Exactitud: 0.785 (+/-0.001) para los parámetros {'C': 1.0, 'max_iter': 10000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 1.0, 'max_iter': 15000, 'tol': 0.001}\n",
      "Exactitud: 0.785 (+/-0.001) para los parámetros {'C': 1.0, 'max_iter': 15000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 1.0, 'max_iter': 20000, 'tol': 0.001}\n",
      "Exactitud: 0.785 (+/-0.001) para los parámetros {'C': 1.0, 'max_iter': 20000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 1.1111111111111112, 'max_iter': 10000, 'tol': 0.001}\n",
      "Exactitud: 0.783 (+/-0.002) para los parámetros {'C': 1.1111111111111112, 'max_iter': 10000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 1.1111111111111112, 'max_iter': 15000, 'tol': 0.001}\n",
      "Exactitud: 0.783 (+/-0.002) para los parámetros {'C': 1.1111111111111112, 'max_iter': 15000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 1.1111111111111112, 'max_iter': 20000, 'tol': 0.001}\n",
      "Exactitud: 0.783 (+/-0.002) para los parámetros {'C': 1.1111111111111112, 'max_iter': 20000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 1.25, 'max_iter': 10000, 'tol': 0.001}\n",
      "Exactitud: 0.782 (+/-0.001) para los parámetros {'C': 1.25, 'max_iter': 10000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 1.25, 'max_iter': 15000, 'tol': 0.001}\n",
      "Exactitud: 0.782 (+/-0.001) para los parámetros {'C': 1.25, 'max_iter': 15000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 1.25, 'max_iter': 20000, 'tol': 0.001}\n",
      "Exactitud: 0.782 (+/-0.001) para los parámetros {'C': 1.25, 'max_iter': 20000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 2.0, 'max_iter': 10000, 'tol': 0.001}\n",
      "Exactitud: 0.785 (+/-0.002) para los parámetros {'C': 2.0, 'max_iter': 10000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 2.0, 'max_iter': 15000, 'tol': 0.001}\n",
      "Exactitud: 0.785 (+/-0.002) para los parámetros {'C': 2.0, 'max_iter': 15000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 2.0, 'max_iter': 20000, 'tol': 0.001}\n",
      "Exactitud: 0.785 (+/-0.002) para los parámetros {'C': 2.0, 'max_iter': 20000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 10.0, 'max_iter': 10000, 'tol': 0.001}\n",
      "Exactitud: 0.783 (+/-0.002) para los parámetros {'C': 10.0, 'max_iter': 10000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 10.0, 'max_iter': 15000, 'tol': 0.001}\n",
      "Exactitud: 0.783 (+/-0.002) para los parámetros {'C': 10.0, 'max_iter': 15000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 10.0, 'max_iter': 20000, 'tol': 0.001}\n",
      "Exactitud: 0.783 (+/-0.002) para los parámetros {'C': 10.0, 'max_iter': 20000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 100.0, 'max_iter': 10000, 'tol': 0.001}\n",
      "Exactitud: 0.778 (+/-0.001) para los parámetros {'C': 100.0, 'max_iter': 10000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 100.0, 'max_iter': 15000, 'tol': 0.001}\n",
      "Exactitud: 0.778 (+/-0.001) para los parámetros {'C': 100.0, 'max_iter': 15000, 'tol': 1e-05}\n",
      "Exactitud: 0.640 (+/-0.003) para los parámetros {'C': 100.0, 'max_iter': 20000, 'tol': 0.001}\n",
      "Exactitud: 0.778 (+/-0.001) para los parámetros {'C': 100.0, 'max_iter': 20000, 'tol': 1e-05}\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       313\n",
      "          1       0.71      0.26      0.38        58\n",
      "\n",
      "avg / total       0.85      0.87      0.84       371\n",
      "\n",
      "\n",
      "============================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f17a2dc7a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "  \n",
    "for idx, penalty in enumerate(('l1', 'l2'), start=1):\n",
    "    exploring_params = {\n",
    "        'C': [1./40., 1./30., 1./20., 1./10., 1./1., 1./0.9, 1./0.8, 1./0.5, 1./0.1, 1./0.01],  # Tasa de regularización\n",
    "        'tol': [1e-3, 1e-5], \n",
    "        'max_iter': [10000, 15000, 20000]\n",
    "    }    \n",
    "    #poly_features = PolynomialFeatures(polynomial_degree)\n",
    "    #poly_features.fit(X_train_feature)\n",
    "    #X_poly_train = poly_features.transform(X_train_feature)\n",
    "    #X_poly_test = poly_features.transform(X_test_feature)\n",
    "    \n",
    "    m = LogisticRegression(penalty=penalty)\n",
    "    model = GridSearchCV(m, exploring_params, cv=5, scoring='roc_auc')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"####################################################################\")\n",
    "    print(\"    Exploración de hiperparámetros para función de coste \\\"%s\\\"    \" % penalty, end=\"\\n\")\n",
    "    print(\"####################################################################\\n\")\n",
    "    \n",
    "    print(\"Mejor conjunto de parámetros:\")\n",
    "    print(model.best_params_, end=\"\\n\\n\")\n",
    "\n",
    "    print(\"Puntajes de la grilla:\", end=\"\\n\")\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "        print(\"Exactitud: %0.3f (+/-%0.03f) para los parámetros %r\" % (mean, std ** 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\", end=\"\\n\")\n",
    "    y_true, y_pred = y_test, model.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred), end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"============================================================================================================\", end=\"\\n\\n\")\n",
    "\n",
    "    plt.subplot(1, 2, idx)\n",
    "    plot_confusion_matrix(confusion_matrix(y_true, y_pred),\n",
    "                          classes=[0,1], title=\"Matriz de confusión para %s\" % penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Ejercicio 4: Métricas sobre el conjunto de evaluación\n",
    "\n",
    "Una vez encontrados los mejores hiperparámetros para el modelo seleccionado en los apartados anteriores se evalúa el modelo final entrenado sobre el conjunto de datos de evaluación seleccionado en el ejercicio 1. Pueden utilizar las métricas que crean convenientes. Es mejor utilizar más de una métrica. Particularmente el *reporte de clasificación* y la *matriz de confusión* son buenos ejemplos de métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-10-73274b20b008>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-73274b20b008>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    model = LogisticRegression(penalty=penalty, C, max_iter=max_iter, tol=tol)\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "penalty = 'l1'  # TODO: Tipo de regularización: l1 (valor absoluto), l2 (cuadrados), elasticnet (l1 + l2).\n",
    "C = 1./0.9      # TODO: Parámetro de regularización. También denominado como parámetro `lambda`.\n",
    "max_iter = 20000 # TODO: Cantidad máxima de iteraciones del algoritmo\n",
    "tol = 0.001      #TODO: Precisión del algoritmo (error mínimo entre una iteración y la siguiente)\n",
    "\n",
    "model = LogisticRegression(penalty=penalty, C=C, max_iter=max_iter, tol=tol)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluamos el desempeño del clasificador utilizando la exactitud (accuracy) sobre el conjunto\n",
    "# de datos de entrenamiento (X_train, y_train) y lo comparamos con el de validación (X_val, y_val)\n",
    "# La exactitud toma valor en el rango [0, 1] donde más alto es mejor\n",
    "print('Exactitud para entrenamiento: %.2f' %  accuracy_score(y_train, model.predict(X_train)))\n",
    "print('Exactitud para validación: %.2f' % accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plot_confusion_matrix(confusion_matrix(y_train, model.predict(X_train)),\n",
    "                classes=[0.1],title='Matriz de confusión para entrenamiento (sin normalizar)')\n",
    "plt.subplot(2, 2, 3)\n",
    "plot_confusion_matrix(confusion_matrix(y_train, model.predict(X_train)),\n",
    "                classes=[0.1],normalize=True,title='Matriz de confusión para entrenamiento (normalizando)')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plot_confusion_matrix(confusion_matrix(y_test, model.predict(X_test)),\n",
    "                classes=[0.1],title='Matriz de confusión para validación (sin normalizar)')\n",
    "plt.subplot(2, 2, 4)\n",
    "plot_confusion_matrix(confusion_matrix(y_test, model.predict(X_test)),\n",
    "                classes=[0.1], normalize=True,title='Matriz de confusión para validación (normalizando)')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Ejercicio 5 (opcional): Curvas de ROC\n",
    "\n",
    "Como ejercicio adicional (opcional), pueden redefinir el umbral de decisión óptimo del problema a partir de los resultados que muestren curvas de ROC como justificación. \n",
    "\n",
    "Pueden ver esto mediante la [graficación de las curvas de ROC](http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html). En el link que se les brinda se muestra como hacer para graficar curvas de ROC para problemas multiclase. Sin embargo se puede adaptar fácilmente a un problema binario obviando la parte donde se calcula la curva clase por clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Redefinir umbral de clasificación a través de los resultados vistos por graficar curvas de ROC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
