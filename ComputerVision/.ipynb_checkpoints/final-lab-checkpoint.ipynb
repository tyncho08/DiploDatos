{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><font size=\"6\">Final Lab: Transfer Learning with [MobileNet](https://arxiv.org/pdf/1704.04861.pdf) and [Cifar-10](https://www.cs.toronto.edu/~kriz/cifar.html)</font></center></h1>\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/800/1*QN007xhxgDTPBdNT0pnZ2g.png\" width=\"400\"></img>\n",
    "\n",
    "# Main task\n",
    "\n",
    "In this notebook, we will apply transfer learning techniques to finetune the [MobileNet](https://arxiv.org/pdf/1704.04861.pdf) CNN on [Cifar-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset.\n",
    "\n",
    "# Procedures\n",
    "\n",
    "In general, the main steps that we will follow are:\n",
    "\n",
    "- <a href='#1'>Load data, analyze and split in *training*/*validation*/*testing* sets</a>  \n",
    "- <a href='#2'>Load CNN and analyze architecture</a>  \n",
    "- <a href='#3'>Adapt this CNN to our problem</a>  \n",
    "- <a href='#4'>Setup data augmentation techniques</a>\n",
    "- <a href='#5'>Add some keras callbacks</a>   \n",
    "- <a href='#6'>Setup optimization algorithm with their hyperparameters</a>  \n",
    "- <a href='#7'>Train model!</a>\n",
    "- <a href='#8'>Choose best model/snapshot</a>\n",
    "- <a href='#9'>Evaluate final model on the *testing* set</a>\n",
    "- <a href='#10'>Conclusions</a>\n",
    "\n",
    "# Students\n",
    "\n",
    "* Maximiliano Armesto\n",
    "* MartÃ­n Gonella\n",
    "\n",
    "# Link to our DiploDatos Repo\n",
    "\n",
    "* https://github.com/tyncho08/DiploDatos\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup one GPU for tensorflow (don't be greedy).\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# The GPU id to use, \"0\", \"1\", etc.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" #Select only one GPU \n",
    "# Use ---> watch -n 1 nvidia-smi (to see GPU use)\n",
    "\n",
    "# https://keras.io/applications/#documentation-for-individual-models\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import SVG\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Limit tensorflow gpu usage.\n",
    "# Maybe you should comment this lines if you run tensorflow on CPU.\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4 #Memory use on GPU\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"1\">Load data, analyze and split in *training*/*validation*/*testing* sets</a>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10 x_train shape: (50000, 32, 32, 3)\n",
      "CIFAR-10 y_train shape: (50000, 1)\n",
      "CIFAR-10 x_test shape: (10000, 32, 32, 3)\n",
      "CIFAR-10 y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Cifar-10 class names\n",
    "# We will create a dictionary for each type of label\n",
    "# This is a mapping from the int class name to \n",
    "# their corresponding string class name\n",
    "LABELS = {\n",
    "    0: \"airplane\",\n",
    "    1: \"automobile\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\"\n",
    "}\n",
    "\n",
    "# Load dataset from keras\n",
    "(x_train_data, y_train_data), (x_test_data, y_test_data) = cifar10.load_data()\n",
    "\n",
    "############\n",
    "# [COMPLETED] \n",
    "# Some prints to see the loaded data dimensions\n",
    "print(\"CIFAR-10 x_train shape: {}\".format(x_train_data.shape))\n",
    "print(\"CIFAR-10 y_train shape: {}\".format(y_train_data.shape))\n",
    "print(\"CIFAR-10 x_test shape: {}\".format(x_test_data.shape))\n",
    "print(\"CIFAR-10 y_test shape: {}\".format(y_test_data.shape))\n",
    "############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some constants\n",
    "IMG_ROWS = 128\n",
    "IMG_COLS = 128\n",
    "NUM_CLASSES = 10\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 2018\n",
    "#Model\n",
    "NO_EPOCHS = 50\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class distribution: Train set images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# [COMPLETED] \n",
    "# Analyze the amount of images for each class\n",
    "# Plot some images to explore how they look\n",
    "############\n",
    "\n",
    "def get_classes_distribution(y_data):\n",
    "    # Get the count for each label\n",
    "    y = np.bincount(y_data)\n",
    "    ii = np.nonzero(y)[0]\n",
    "    label_counts = zip(ii, y[ii])\n",
    "\n",
    "    # Get total number of samples\n",
    "    total_samples = len(y_data)\n",
    "\n",
    "    # Count the number of items in each class\n",
    "    for label, count in label_counts:\n",
    "        class_name = LABELS[label]\n",
    "        percent = (count / total_samples) * 100\n",
    "        print(\"{:<15s}:  {} or {:.2f}%\".format(class_name, count, percent))\n",
    "        \n",
    "    return label_counts\n",
    "\n",
    "train_label_counts = get_classes_distribution(np.reshape(y_train_data, len(y_train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_label_per_class(y_data):\n",
    "    \n",
    "    classes = sorted(np.unique(y_data))\n",
    "    f, ax = plt.subplots(1,1, figsize=(12, 4))\n",
    "    g = sns.countplot(y_data, order=classes)\n",
    "    g.set_title(\"Number of labels for each class\")\n",
    "    \n",
    "    for p, label in zip(g.patches, classes):\n",
    "        g.annotate(LABELS[label], (p.get_x(), p.get_height() + 0.2))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "plot_label_per_class(y_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class distribution: Test set images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_classes_distribution(np.reshape(y_test_data, len(y_test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_label_per_class(y_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images: Train set\n",
    "\n",
    "Let's plot some samples for the images.   \n",
    "We add labels to the train set images, with the corresponding CIFAR-10 item category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images_data(x_data, y_data):\n",
    "    # An empty list to collect some samples\n",
    "    sample_images = []\n",
    "    sample_labels = []\n",
    "\n",
    "    # Iterate over the keys of the labels dictionary defined in the above cell\n",
    "    for k in LABELS.keys():\n",
    "        # Get four samples for each category\n",
    "        samples = np.where(y_data == k)[0][:4]\n",
    "        # Append the samples to the samples list\n",
    "        for s in samples:\n",
    "            img = x_data[s]\n",
    "            sample_images.append(img)\n",
    "            sample_labels.append(y_data[s])\n",
    "\n",
    "    print(\"Total number of sample images to plot: \", len(sample_images))\n",
    "    return sample_images, sample_labels\n",
    "\n",
    "train_sample_images, train_sample_labels = sample_images_data(x_train_data, y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_images(data_sample_images, data_sample_labels, cmap=\"gray\"):\n",
    "    # Plot the sample images now\n",
    "    f, ax = plt.subplots(5, 8, figsize=(16, 10))\n",
    "\n",
    "    for i, img in enumerate(data_sample_images):\n",
    "        ax[i//8, i%8].imshow(img, cmap=cmap)\n",
    "        ax[i//8, i%8].axis('off')\n",
    "        ax[i//8, i%8].set_title(LABELS[data_sample_labels[i]])\n",
    "    plt.show()    \n",
    "    \n",
    "plot_sample_images(train_sample_images, train_sample_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images: Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample_images, test_sample_labels = sample_images_data(x_test_data, y_test_data)\n",
    "plot_sample_images(test_sample_images, test_sample_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(x_data, y_data):\n",
    "    out_y = to_categorical(y_data, len(np.unique(y_data)))\n",
    "    num_images = x_data.shape[0]\n",
    "    x_shaped_array = np.expand_dims(x_data, axis=-1)\n",
    "    out_x = x_shaped_array / 255.\n",
    "    \n",
    "    return out_x, out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "X, y = data_preprocessing(x_train_data, y_train_data)\n",
    "X_test, y_test = data_preprocessing(x_test_data, y_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train in train and validation set\n",
    "\n",
    "We further split the train set in train and validation set. The validation set will be 20% from the original train set, therefore the split will be train/validation of 0.8/0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# [COMPLETED] \n",
    "# Split training set in train/val sets\n",
    "# Use the sampling method that you want\n",
    "############\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "print(\"CIFAR-10 X_train  -  rows: {}  columns: {}\".format(X_train.shape[0], X_train.shape[1:4]))\n",
    "print(\"CIFAR-10 X_valid  -  rows: {}  columns: {}\".format(X_val.shape[0], X_val.shape[1:4]))\n",
    "print(\"CIFAR-10 X_test   -  rows: {}  columns: {}\".format(X_test.shape[0], X_test.shape[1:4]))\n",
    "print(\"-----------------------------------------------------------\")\n",
    "print(\"CIFAR-10 y_train  -  rows: {}  columns: {}\".format(y_train.shape[0], y_train.shape[1]))\n",
    "print(\"CIFAR-10 y_valid  -  rows: {}  columns: {}\".format(y_val.shape[0], y_val.shape[1]))\n",
    "print(\"CIFAR-10 y_test   -  rows: {}  columns: {}\".format(y_test.shape[0], y_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_classes_distribution(np.argmax(y_train, axis=1))\n",
    "plot_label_per_class(np.argmax(y_train, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_classes_distribution(np.argmax(y_val, axis=1))\n",
    "plot_label_per_class(np.argmax(y_val, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset to disk\n",
    "\n",
    "def save_to_disk(x_data, y_data, usage, output_dir='cifar10_images'):\n",
    "    \"\"\"    \n",
    "    x_data : np.ndarray\n",
    "        Array with images.\n",
    "    \n",
    "    y_data : np.ndarray\n",
    "        Array with labels.\n",
    "    \n",
    "    usage : str\n",
    "        One of ['train', 'val', 'test'].\n",
    "\n",
    "    output_dir : str\n",
    "        Path to save data.\n",
    "    \"\"\"\n",
    "    assert usage in ['train', 'val', 'test']\n",
    "    \n",
    "    # Set paths \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    for label in np.unique(y_data):\n",
    "        label_path = os.path.join(output_dir, usage, str(label))\n",
    "        if not os.path.exists(label_path):\n",
    "            os.makedirs(label_path)\n",
    "    \n",
    "    for idx, img in enumerate(x_data):\n",
    "        bgr_img = img[..., ::-1]  # RGB -> BGR\n",
    "        label = y_data[idx][0]\n",
    "        img_path = os.path.join(output_dir, usage, str(label), 'img_{}.jpg'.format(idx))\n",
    "\n",
    "        retval = cv2.imwrite(img_path, bgr_img)\n",
    "        assert retval, 'Problem saving image at index:{}'.format(idx)\n",
    "\n",
    "\n",
    "############\n",
    "# [COMPLETED] \n",
    "# Use the above function to save all your data, e.g.:\n",
    "save_to_disk(x_train, y_train, 'data/train', 'cifar10_images')\n",
    "save_to_disk(x_val, y_val, 'data/val', 'cifar10_images')\n",
    "save_to_disk(x_test, y_test, 'data/test', 'cifar10_images')\n",
    "############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"2\">Load CNN and analyze architecture</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# [COMPLETED] \n",
    "# Use the MobileNet class from Keras to load your base model, pre-trained on imagenet.\n",
    "# We wan't to load the pre-trained weights, but without the classification layer.\n",
    "# Check the notebook '3_transfer-learning' or https://keras.io/applications/#mobilenet to get more\n",
    "# info about how to load this network properly.\n",
    "############\n",
    "\n",
    "base_model = MobileNet(input_shape=(NET_IMG_ROWS, NET_IMG_COLS, 3), # Input image size\n",
    "                       alpha = 1                                    # default nÂ° of filters from the paper are used at each layer.\n",
    "                       weights='imagenet',                          # Use imagenet pre-trained weights\n",
    "                       include_top=False,                           # Drop classification layer\n",
    "                       pooling='avg')                               # Global AVG pooling for output feature vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_fig = 'Models_Figs/'\n",
    "if not os.path.exists(output_dir_fig):\n",
    "        os.makedirs(output_dir_fig)\n",
    "        \n",
    "plot_model(model, to_file='Models_Figs/base_model.png')\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"3\">Adapt this CNN to our problem</a> \n",
    "\n",
    "### We add some layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# [COMPLETED] \n",
    "# Having the CNN loaded, now we have to add some layers to adapt this network to our\n",
    "# classification problem.\n",
    "# We can choose to finetune just the new added layers, some particular layers or all the layer of the\n",
    "# model. Play with different settings and compare the results.\n",
    "############\n",
    "\n",
    "# get the output feature vector from the base model\n",
    "x = base_model.output\n",
    "\n",
    "# let's add a fully-connected layer with dropout\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# let's add a fully-connected layer  with dropout\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "# let's add a fully-connected layer  with dropout\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "# and a logistic layer\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the final model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='Models_Figs/adapted_model.png')\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"4\">Setup data augmentation techniques</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# [COMPLETED] \n",
    "# Use data augmentation to train your model.\n",
    "# Use the Keras ImageDataGenerator class for this porpouse.\n",
    "# Note: Given that we want to load our images from disk, instead of using \n",
    "# ImageDataGenerator.flow method, we have to use ImageDataGenerator.flow_from_directory \n",
    "# method in the following way:\n",
    "#    generator_train = dataget_train.flow_from_directory('resized_images/train', \n",
    "#                                                        target_size=(128, 128), batch_size=32)\n",
    "#    generator_val = dataget_train.flow_from_directory('resized_images/val', \n",
    "#                                                      target_size=(128, 128), batch_size=32)\n",
    "# Note that we have to resize our images to finetune the MobileNet CNN, this is done using \n",
    "# the target_size argument in flow_from_directory. Remember to set the target_size to one of\n",
    "# the valid listed here: [(128, 128), (160, 160), (192, 192), or (224, 224)].\n",
    "############\n",
    "\n",
    "# Training data generator\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip = False\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    featurewise_center=True,\n",
    "    samplewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    zca_whitening=True\n",
    "    )\n",
    "\n",
    "# Validation data generator\n",
    "datagen_val = ImageDataGenerator(\n",
    "    rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"5\">Add some keras callbackse</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# [COMPLETE] \n",
    "# Load and set some Keras callbacks here!\n",
    "############\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "EXP_ID = 'logs/experiment_000/'\n",
    "\n",
    "if not os.path.exists(EXP_ID):\n",
    "    os.makedirs(EXP_ID)\n",
    "\n",
    "callbacks = [ModelCheckpoint(filepath=os.path.join(EXP_ID, 'weights.{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "                    monitor='val_loss', \n",
    "                    verbose=1, \n",
    "                    save_best_only=False, \n",
    "                    save_weights_only=False, \n",
    "                    mode='auto'),\n",
    "             EarlyStopping(monitor='val_loss', \n",
    "                  min_delta=0, \n",
    "                  patience=2, \n",
    "                  verbose=1, \n",
    "                  mode='auto', \n",
    "                  baseline=None, \n",
    "                  restore_best_weights=False),\n",
    "             TensorBoard(log_dir=os.path.join(EXP_ID, 'logs'), \n",
    "                write_graph=True, \n",
    "                write_images=False),\n",
    "             ReduceLROnPlateau(monitor='val_loss', \n",
    "                      factor=0.1, \n",
    "                      patience=10, \n",
    "                      verbose=0, \n",
    "                      mode='auto')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have installed TensorFlow with pip, you should be able to launch TensorBoard from the command line:\n",
    "\n",
    "```\n",
    "tensorboard --logdir=/full_path_to_your_logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"6\">Setup optimization algorithm with their hyperparameters</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# [COMPLETE] \n",
    "# Choose some optimization algorithm and explore different hyperparameters.\n",
    "# Compile your model.\n",
    "############\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "#Choose one optimizer\n",
    "optimizador = optimizers.SGD(lr=0.0001, momentum=0.9)\n",
    "#optimizador = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "#optimizador = optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "#optimizador = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "#optimizador = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "#optimizador = optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizador,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"7\">Train model!</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# [COMPLETE] \n",
    "# Use fit_generator to train your model.\n",
    "# e.g.:\n",
    "#    model.fit_generator(\n",
    "#        generator_train,\n",
    "#        epochs=50,\n",
    "#        validation_data=generator_val,\n",
    "#        steps_per_epoch=generator_train.n // 32,\n",
    "#        validation_steps=generator_val.n // 32)\n",
    "############\n",
    "\n",
    "'''train_model = model.fit_generator(\n",
    "    datagen_train.flow(X_train, y_train, target_size=(IMG_ROWS,IMG_COLS), batch_size=BATCH_SIZE),\n",
    "    epochs=NO_EPOCHS,\n",
    "    validation_data=datagen_val.flow(X_val, y_val, target_size=(IMG_ROWS,IMG_COLS), batch_size=BATCH_SIZE),\n",
    "    steps_per_epoch=X_train.shape[0] // BATCH_SIZE,\n",
    "    validation_steps=X_val.shape[0] // BATCH_SIZE,\n",
    "    callbacks=callbacks)'''\n",
    "\n",
    "train_model = model.fit_generator(\n",
    "    datagen_train.flow_from_directory('data/train', \n",
    "                                      target_size=(IMG_ROWS,IMG_COLS), \n",
    "                                      batch_size=BATCH_SIZE)\n",
    "    validation_data=datagen_val.flow_from_directory('data/val', \n",
    "                                                    target_size=(IMG_ROWS,IMG_COLS), \n",
    "                                                    batch_size=BATCH_SIZE),\n",
    "    steps_per_epoch=X_train.shape[0] // BATCH_SIZE,\n",
    "    validation_steps=X_val.shape[0] // BATCH_SIZE,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"8\">Choose best model/snapshot</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TensorBoard, I evaluated the model and his results. So, I can say that the best choise is the next one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# [COMPLETE] \n",
    "# Analyze and compare your results. Choose the best model and snapshot, \n",
    "# justify your election. \n",
    "############\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"9\">Evaluate final model on the *testing* set</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# [COMPLETED] \n",
    "# Evaluate your model on the testing set.\n",
    "############\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation accuracy and loss\n",
    "\n",
    "Let's plot the train and validation accuracy and loss, from the train history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_and_loss(train_model):\n",
    "    hist = train_model.history\n",
    "    acc = hist['acc']\n",
    "    val_acc = hist['val_acc']\n",
    "    loss = hist['loss']\n",
    "    val_loss = hist['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "    f, ax = plt.subplots(1,2, figsize=(14,6))\n",
    "    ax[0].plot(epochs, acc, 'g', label='Training accuracy')\n",
    "    ax[0].plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "    ax[0].set_title('Training and validation accuracy')\n",
    "    ax[0].legend()\n",
    "    ax[1].plot(epochs, loss, 'g', label='Training loss')\n",
    "    ax[1].plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    ax[1].set_title('Training and validation loss')\n",
    "    ax[1].legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_accuracy_and_loss(train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions for the test data\n",
    "predicted_classes = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = predicted_classes\n",
    "y = y_test_data\n",
    "correct = np.nonzero(p == y)[0]\n",
    "incorrect = np.nonzero(p != y)[0]\n",
    "\n",
    "print(\"Correct predicted classes:\", correct.shape[0])\n",
    "print(\"Incorrect predicted classes:\", incorrect.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = [\"Class {} ({}) :\".format(i, LABELS[i]) for i in range(NUM_CLASSES)]\n",
    "print(classification_report(y_test_data, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize classified images\n",
    "\n",
    "#### Correctly classified images\n",
    "\n",
    "We visualize few images correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predicted_images(predictions, data_index, x_data, y_data, size=16, cmap=\"gray\"):\n",
    "    # Plot the sample images now\n",
    "    f, ax = plt.subplots(4, 4, figsize=(15, 15))\n",
    "\n",
    "    for i, indx in enumerate(np.random.choice(data_index, size=size, replace=False)):\n",
    "        ax[i//4, i%4].imshow(x_data[indx].reshape(IMG_ROWS,IMG_COLS), cmap=cmap)\n",
    "        ax[i//4, i%4].axis('off')\n",
    "        ax[i//4, i%4].set_title(\"True:{}  Pred:{}\".format(LABELS[y_data[indx]], LABELS[predicted_classes[indx]]))\n",
    "    plt.show()    \n",
    "    \n",
    "plot_predicted_images(predicted_classes, correct, x_test_data, y_test_data, cmap=\"Greens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorrectly classified images\n",
    "\n",
    "Let's see also few images incorrectly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicted_images(predicted_classes, incorrect, x_test_data, y_test_data, cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"10\">Conclusions</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here come the bright conclusions that i could extract from the results ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
