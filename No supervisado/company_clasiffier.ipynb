{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "import progressbar\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_files('Dataset/descriptions', shuffle=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['target_names', 'filenames', 'data', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuweather',\n",
       " 'allianz',\n",
       " 'amazon',\n",
       " 'citigroup',\n",
       " 'fujitsu',\n",
       " 'garmin',\n",
       " 'github',\n",
       " 'ibm',\n",
       " 'metlife',\n",
       " 'uber',\n",
       " 'yahoo',\n",
       " 'zurich']"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'data': dataset['data'], 'target': dataset['target']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'help organizations move faster, lower IT costs, and scale applications'"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['target'] == 2].data[44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset.data,\n",
    "    dataset.target,\n",
    "    test_size=0.0001, # For Overfitting\n",
    "    #test_size=0.15,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 20,\n",
       "          1: 23,\n",
       "          2: 28,\n",
       "          3: 23,\n",
       "          4: 21,\n",
       "          5: 20,\n",
       "          6: 20,\n",
       "          7: 20,\n",
       "          8: 20,\n",
       "          9: 19,\n",
       "          10: 19,\n",
       "          11: 19}),\n",
       " Counter({9: 1}))"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train), Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x692 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = vect.transform([X_train[0]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(38, 1), (105, 1), (143, 1), (273, 1), (309, 1), (398, 1), (486, 1), (533, 1)]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, x[0, i]) for i in range(662) if x[0, i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '100',\n",
       " '147',\n",
       " '159',\n",
       " '160',\n",
       " '175',\n",
       " '200',\n",
       " '50',\n",
       " '70',\n",
       " '90',\n",
       " 'ability',\n",
       " 'access',\n",
       " 'accessed',\n",
       " 'accessible',\n",
       " 'accident',\n",
       " 'accordingly',\n",
       " 'accounts',\n",
       " 'accuweather',\n",
       " 'across',\n",
       " 'activity',\n",
       " 'adapt',\n",
       " 'administration',\n",
       " 'advances',\n",
       " 'advantage',\n",
       " 'advertisers',\n",
       " 'advertising',\n",
       " 'advises',\n",
       " 'affiliate',\n",
       " 'agency',\n",
       " 'aims',\n",
       " 'aircraft',\n",
       " 'all',\n",
       " 'allianz',\n",
       " 'also',\n",
       " 'amazon',\n",
       " 'an',\n",
       " 'analysis',\n",
       " 'analytics',\n",
       " 'and',\n",
       " 'annuities',\n",
       " 'anywhere',\n",
       " 'apis',\n",
       " 'application',\n",
       " 'applications',\n",
       " 'approximately',\n",
       " 'apps',\n",
       " 'archive',\n",
       " 'are',\n",
       " 'areas',\n",
       " 'armed',\n",
       " 'around',\n",
       " 'array',\n",
       " 'art',\n",
       " 'as',\n",
       " 'ask',\n",
       " 'asset',\n",
       " 'at',\n",
       " 'atm',\n",
       " 'automated',\n",
       " 'automotive',\n",
       " 'available',\n",
       " 'aviation',\n",
       " 'aws',\n",
       " 'backed',\n",
       " 'bank',\n",
       " 'banking',\n",
       " 'banks',\n",
       " 'barcode',\n",
       " 'based',\n",
       " 'be',\n",
       " 'beat',\n",
       " 'because',\n",
       " 'been',\n",
       " 'benefit',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'big',\n",
       " 'both',\n",
       " 'branches',\n",
       " 'brand',\n",
       " 'brighthouse',\n",
       " 'bring',\n",
       " 'broad',\n",
       " 'brokerage',\n",
       " 'bug',\n",
       " 'build',\n",
       " 'builds',\n",
       " 'built',\n",
       " 'business',\n",
       " 'businesses',\n",
       " 'by',\n",
       " 'called',\n",
       " 'can',\n",
       " 'car',\n",
       " 'card',\n",
       " 'casualty',\n",
       " 'changes',\n",
       " 'changing',\n",
       " 'channels',\n",
       " 'cities',\n",
       " 'citigroup',\n",
       " 'citizens',\n",
       " 'claims',\n",
       " 'class',\n",
       " 'clients',\n",
       " 'closer',\n",
       " 'cloud',\n",
       " 'cloudiness',\n",
       " 'code',\n",
       " 'collaborating',\n",
       " 'collaboration',\n",
       " 'collapse',\n",
       " 'college',\n",
       " 'commercial',\n",
       " 'commitments',\n",
       " 'committed',\n",
       " 'communication',\n",
       " 'communications',\n",
       " 'communities',\n",
       " 'community',\n",
       " 'companies',\n",
       " 'company',\n",
       " 'companys',\n",
       " 'competitive',\n",
       " 'completed',\n",
       " 'complex',\n",
       " 'complexities',\n",
       " 'compute',\n",
       " 'computer',\n",
       " 'computers',\n",
       " 'computing',\n",
       " 'conduct',\n",
       " 'connecting',\n",
       " 'connects',\n",
       " 'consulting',\n",
       " 'consumer',\n",
       " 'consumers',\n",
       " 'content',\n",
       " 'continues',\n",
       " 'contribute',\n",
       " 'control',\n",
       " 'conventions',\n",
       " 'corporate',\n",
       " 'corporation',\n",
       " 'corporations',\n",
       " 'costs',\n",
       " 'countries',\n",
       " 'create',\n",
       " 'credit',\n",
       " 'customer',\n",
       " 'customers',\n",
       " 'data',\n",
       " 'database',\n",
       " 'debt',\n",
       " 'decisions',\n",
       " 'delivery',\n",
       " 'dental',\n",
       " 'deployment',\n",
       " 'derived',\n",
       " 'designed',\n",
       " 'detailed',\n",
       " 'developers',\n",
       " 'did',\n",
       " 'different',\n",
       " 'dimensions',\n",
       " 'disability',\n",
       " 'disk',\n",
       " 'distribute',\n",
       " 'distributed',\n",
       " 'distribution',\n",
       " 'diverse',\n",
       " 'diversified',\n",
       " 'do',\n",
       " 'does',\n",
       " 'dominant',\n",
       " 'done',\n",
       " 'dram',\n",
       " 'drive',\n",
       " 'driver',\n",
       " 'drivers',\n",
       " 'due',\n",
       " 'dynamic',\n",
       " 'early',\n",
       " 'easier',\n",
       " 'economy',\n",
       " 'education',\n",
       " 'efficiencies',\n",
       " 'electronic',\n",
       " 'employ',\n",
       " 'employee',\n",
       " 'employees',\n",
       " 'enable',\n",
       " 'energy',\n",
       " 'engine',\n",
       " 'enormous',\n",
       " 'enterprises',\n",
       " 'entities',\n",
       " 'environmental',\n",
       " 'era',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everywhere',\n",
       " 'evolve',\n",
       " 'exchanges',\n",
       " 'expanding',\n",
       " 'expenses',\n",
       " 'experience',\n",
       " 'explosion',\n",
       " 'extends',\n",
       " 'external',\n",
       " 'families',\n",
       " 'farmers',\n",
       " 'faster',\n",
       " 'feature',\n",
       " 'features',\n",
       " 'finance',\n",
       " 'financial',\n",
       " 'fire',\n",
       " 'first',\n",
       " 'five',\n",
       " 'fixed',\n",
       " 'flight',\n",
       " 'floppy',\n",
       " 'fluctuations',\n",
       " 'focus',\n",
       " 'for',\n",
       " 'forces',\n",
       " 'forecast',\n",
       " 'forecasting',\n",
       " 'forecasts',\n",
       " 'free',\n",
       " 'from',\n",
       " 'front',\n",
       " 'fujitsu',\n",
       " 'full',\n",
       " 'fun',\n",
       " 'functions',\n",
       " 'future',\n",
       " 'gain',\n",
       " 'garmin',\n",
       " 'garmins',\n",
       " 'gathered',\n",
       " 'general',\n",
       " 'generated',\n",
       " 'geospatial',\n",
       " 'get',\n",
       " 'github',\n",
       " 'gives',\n",
       " 'giving',\n",
       " 'global',\n",
       " 'globe',\n",
       " 'go',\n",
       " 'goes',\n",
       " 'government',\n",
       " 'governments',\n",
       " 'gps',\n",
       " 'greatest',\n",
       " 'group',\n",
       " 'guaranteed',\n",
       " 'happenz',\n",
       " 'hard',\n",
       " 'hardware',\n",
       " 'harness',\n",
       " 'has',\n",
       " 'have',\n",
       " 'headquarters',\n",
       " 'health',\n",
       " 'held',\n",
       " 'help',\n",
       " 'helping',\n",
       " 'helps',\n",
       " 'high',\n",
       " 'history',\n",
       " 'holding',\n",
       " 'home',\n",
       " 'host',\n",
       " 'hosting',\n",
       " 'hottest',\n",
       " 'house',\n",
       " 'how',\n",
       " 'ibm',\n",
       " 'ibmers',\n",
       " 'ict',\n",
       " 'if',\n",
       " 'illustrate',\n",
       " 'impact',\n",
       " 'improve',\n",
       " 'in',\n",
       " 'inc',\n",
       " 'include',\n",
       " 'included',\n",
       " 'includes',\n",
       " 'including',\n",
       " 'income',\n",
       " 'increase',\n",
       " 'indicating',\n",
       " 'individual',\n",
       " 'individuals',\n",
       " 'industries',\n",
       " 'industry',\n",
       " 'infinite',\n",
       " 'information',\n",
       " 'infrastructure',\n",
       " 'injury',\n",
       " 'innovation',\n",
       " 'insight',\n",
       " 'instead',\n",
       " 'institutional',\n",
       " 'institutions',\n",
       " 'instrumented',\n",
       " 'insurance',\n",
       " 'integrated',\n",
       " 'integration',\n",
       " 'intelligent',\n",
       " 'intensity',\n",
       " 'interactions',\n",
       " 'interconnected',\n",
       " 'interfaces',\n",
       " 'international',\n",
       " 'internet',\n",
       " 'into',\n",
       " 'inventions',\n",
       " 'investment',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'japanese',\n",
       " 'japans',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'keeps',\n",
       " 'language',\n",
       " 'largest',\n",
       " 'leaders',\n",
       " 'leading',\n",
       " 'lending',\n",
       " 'lets',\n",
       " 'life',\n",
       " 'local',\n",
       " 'location',\n",
       " 'locations',\n",
       " 'long',\n",
       " 'look',\n",
       " 'lost',\n",
       " 'lower',\n",
       " 'machine',\n",
       " 'machines',\n",
       " 'made',\n",
       " 'magnetic',\n",
       " 'mainframe',\n",
       " 'major',\n",
       " 'make',\n",
       " 'making',\n",
       " 'management',\n",
       " 'manufactured',\n",
       " 'manufactures',\n",
       " 'many',\n",
       " 'marine',\n",
       " 'market',\n",
       " 'marketing',\n",
       " 'markets',\n",
       " 'me',\n",
       " 'media',\n",
       " 'medium',\n",
       " 'memory',\n",
       " 'meteorological',\n",
       " 'meteorologists',\n",
       " 'metlife',\n",
       " 'metropolitan',\n",
       " 'middleware',\n",
       " 'might',\n",
       " 'million',\n",
       " 'mind',\n",
       " 'mix',\n",
       " 'mobile',\n",
       " 'model',\n",
       " 'more',\n",
       " 'mortgages',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'motor',\n",
       " 'move',\n",
       " 'moves',\n",
       " 'much',\n",
       " 'multinational',\n",
       " 'multivariate',\n",
       " 'mutual',\n",
       " 'mutualization',\n",
       " 'my',\n",
       " 'name',\n",
       " 'nanotechnology',\n",
       " 'national',\n",
       " 'nature',\n",
       " 'navigating',\n",
       " 'navigation',\n",
       " 'need',\n",
       " 'net',\n",
       " 'network',\n",
       " 'new',\n",
       " 'no',\n",
       " 'non',\n",
       " 'not',\n",
       " 'now',\n",
       " 'number',\n",
       " 'numerous',\n",
       " 'observations',\n",
       " 'observe',\n",
       " 'of',\n",
       " 'offer',\n",
       " 'offering',\n",
       " 'offerings',\n",
       " 'offers',\n",
       " 'offices',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'online',\n",
       " 'only',\n",
       " 'open',\n",
       " 'opening',\n",
       " 'operated',\n",
       " 'operating',\n",
       " 'operations',\n",
       " 'or',\n",
       " 'organization',\n",
       " 'organizations',\n",
       " 'other',\n",
       " 'others',\n",
       " 'our',\n",
       " 'outdoor',\n",
       " 'outside',\n",
       " 'over',\n",
       " 'owned',\n",
       " 'pa',\n",
       " 'partner',\n",
       " 'party',\n",
       " 'patents',\n",
       " 'pause',\n",
       " 'pay',\n",
       " 'paying',\n",
       " 'pc',\n",
       " 'peace',\n",
       " 'peer',\n",
       " 'pension',\n",
       " 'people',\n",
       " 'period',\n",
       " 'perspectives',\n",
       " 'physical',\n",
       " 'pioneers',\n",
       " 'plan',\n",
       " 'planet',\n",
       " 'plans',\n",
       " 'platform',\n",
       " 'platforms',\n",
       " 'please',\n",
       " 'policies',\n",
       " 'political',\n",
       " 'portal',\n",
       " 'portion',\n",
       " 'possibilities',\n",
       " 'power',\n",
       " 'powerful',\n",
       " 'precipitation',\n",
       " 'presence',\n",
       " 'price',\n",
       " 'private',\n",
       " 'process',\n",
       " 'processing',\n",
       " 'product',\n",
       " 'products',\n",
       " 'programmers',\n",
       " 'programming',\n",
       " 'programs',\n",
       " 'project',\n",
       " 'projects',\n",
       " 'prominent',\n",
       " 'properties',\n",
       " 'property',\n",
       " 'proprietary',\n",
       " 'protection',\n",
       " 'provide',\n",
       " 'provided',\n",
       " 'provider',\n",
       " 'provides',\n",
       " 'public',\n",
       " 'publishers',\n",
       " 'purpose',\n",
       " 'quality',\n",
       " 'random',\n",
       " 'range',\n",
       " 'ranging',\n",
       " 'rapidly',\n",
       " 're',\n",
       " 'reach',\n",
       " 'reassessing',\n",
       " 'recognition',\n",
       " 'record',\n",
       " 'redesigning',\n",
       " 'reduce',\n",
       " 'reference',\n",
       " 'referred',\n",
       " 'regions',\n",
       " 'related',\n",
       " 'relational',\n",
       " 'replace',\n",
       " 'replaced',\n",
       " 'repositories',\n",
       " 'requests',\n",
       " 'research',\n",
       " 'resources',\n",
       " 'rest',\n",
       " 'result',\n",
       " 'retail',\n",
       " 'retailing',\n",
       " 'retirees',\n",
       " 'retirement',\n",
       " 'review',\n",
       " 'ride',\n",
       " 'riders',\n",
       " 'ridesharing',\n",
       " 'risk',\n",
       " 'risks',\n",
       " 'roles',\n",
       " 'room',\n",
       " 'safety',\n",
       " 'savings',\n",
       " 'scale',\n",
       " 'science',\n",
       " 'seamlessly',\n",
       " 'search',\n",
       " 'seat',\n",
       " 'sector',\n",
       " 'secure',\n",
       " 'securities',\n",
       " 'see',\n",
       " 'seen',\n",
       " 'segment',\n",
       " 'separate',\n",
       " 'serve',\n",
       " 'serves',\n",
       " 'service',\n",
       " 'services',\n",
       " 'serving',\n",
       " 'set',\n",
       " 'settlements',\n",
       " 'several',\n",
       " 'shape',\n",
       " 'shaping',\n",
       " 'shareholders',\n",
       " 'sharing',\n",
       " 'shortages',\n",
       " 'should',\n",
       " 'shows',\n",
       " 'sickness',\n",
       " 'single',\n",
       " 'sites',\n",
       " 'sized',\n",
       " 'sizes',\n",
       " 'small',\n",
       " 'smart',\n",
       " 'smarter',\n",
       " 'smartwatch',\n",
       " 'so',\n",
       " 'social',\n",
       " 'society',\n",
       " 'software',\n",
       " 'solutions',\n",
       " 'source',\n",
       " 'sources',\n",
       " 'sovereign',\n",
       " 'specialize',\n",
       " 'specializes',\n",
       " 'specify',\n",
       " 'spoon',\n",
       " 'sports',\n",
       " 'sql',\n",
       " 'start',\n",
       " 'starting',\n",
       " 'state',\n",
       " 'states',\n",
       " 'storage',\n",
       " 'store',\n",
       " 'strategic',\n",
       " 'stripe',\n",
       " 'structured',\n",
       " 'success',\n",
       " 'such',\n",
       " 'sunshine',\n",
       " 'support',\n",
       " 'swiss',\n",
       " 'systems',\n",
       " 'task',\n",
       " 'teams',\n",
       " 'technical',\n",
       " 'technology',\n",
       " 'teller',\n",
       " 'temperature',\n",
       " 'tenth',\n",
       " 'term',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'these',\n",
       " 'they',\n",
       " 'think',\n",
       " 'third',\n",
       " 'this',\n",
       " 'through',\n",
       " 'timelines',\n",
       " 'to',\n",
       " 'today',\n",
       " 'together',\n",
       " 'tomorrow',\n",
       " 'tool',\n",
       " 'tools',\n",
       " 'top',\n",
       " 'touch',\n",
       " 'tracker',\n",
       " 'tracking',\n",
       " 'transform',\n",
       " 'trends',\n",
       " 'trusted',\n",
       " 'two',\n",
       " 'types',\n",
       " 'uber',\n",
       " 'uberisation',\n",
       " 'ubers',\n",
       " 'unable',\n",
       " 'united',\n",
       " 'universally',\n",
       " 'unrest',\n",
       " 'up',\n",
       " 'upc',\n",
       " 'ups',\n",
       " 'us',\n",
       " 'use',\n",
       " 'used',\n",
       " 'users',\n",
       " 'uses',\n",
       " 'using',\n",
       " 'variable',\n",
       " 'varied',\n",
       " 'variety',\n",
       " 'various',\n",
       " 've',\n",
       " 'version',\n",
       " 'vertical',\n",
       " 'verticals',\n",
       " 'very',\n",
       " 'via',\n",
       " 'visit',\n",
       " 'warehousing',\n",
       " 'warning',\n",
       " 'was',\n",
       " 'water',\n",
       " 'way',\n",
       " 'ways',\n",
       " 'we',\n",
       " 'weather',\n",
       " 'web',\n",
       " 'website',\n",
       " 'websites',\n",
       " 'what',\n",
       " 'where',\n",
       " 'which',\n",
       " 'who',\n",
       " 'wide',\n",
       " 'wikis',\n",
       " 'will',\n",
       " 'winners',\n",
       " 'with',\n",
       " 'without',\n",
       " 'work',\n",
       " 'working',\n",
       " 'workloads',\n",
       " 'works',\n",
       " 'world',\n",
       " 'worlds',\n",
       " 'worldwide',\n",
       " 'worth',\n",
       " 'write',\n",
       " 'writing',\n",
       " 'yahoo',\n",
       " 'years',\n",
       " 'yesterday',\n",
       " 'you',\n",
       " 'your',\n",
       " 'zurich']"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = vect.get_feature_names()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 1),\n",
       " ('clients', 1),\n",
       " ('corporate', 1),\n",
       " ('high', 1),\n",
       " ('institutional', 1),\n",
       " ('net', 1),\n",
       " ('public', 1),\n",
       " ('sector', 1),\n",
       " ('worth', 1)]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(features[i], x[0, i]) for i in range(x.shape[1]) if x[0, i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [\n",
    "    KNeighborsClassifier(),\n",
    "    MultinomialNB(),\n",
    "    DecisionTreeClassifier(max_depth = 2, random_state=0),\n",
    "    LogisticRegression(random_state=0),\n",
    "    LinearSVC(random_state=0),\n",
    "    SVC(random_state=0),\n",
    "    RandomForestClassifier(random_state=0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "accuweather       0.26      0.93      0.41        14\n",
      "    allianz       0.47      0.89      0.62        19\n",
      "     amazon       0.70      0.78      0.74        27\n",
      "  citigroup       0.84      0.76      0.80        21\n",
      "    fujitsu       0.76      0.68      0.72        19\n",
      "     garmin       0.92      0.71      0.80        17\n",
      "     github       0.82      0.53      0.64        17\n",
      "        ibm       0.88      0.79      0.83        19\n",
      "    metlife       1.00      0.11      0.20        18\n",
      "       uber       0.86      0.43      0.57        14\n",
      "      yahoo       1.00      0.36      0.53        14\n",
      "     zurich       1.00      0.50      0.67        16\n",
      "\n",
      "avg / total       0.79      0.64      0.64       215\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "accuweather       0.24      0.83      0.37         6\n",
      "    allianz       0.75      0.75      0.75         4\n",
      "     amazon       0.33      1.00      0.50         1\n",
      "  citigroup       0.00      0.00      0.00         2\n",
      "    fujitsu       0.00      0.00      0.00         2\n",
      "     garmin       0.67      0.67      0.67         3\n",
      "     github       1.00      0.67      0.80         3\n",
      "        ibm       0.00      0.00      0.00         1\n",
      "    metlife       0.00      0.00      0.00         2\n",
      "       uber       1.00      0.33      0.50         6\n",
      "      yahoo       0.00      0.00      0.00         5\n",
      "     zurich       1.00      0.33      0.50         3\n",
      "\n",
      "avg / total       0.49      0.42      0.38        38\n",
      "\n",
      "<class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "accuweather       1.00      1.00      1.00        14\n",
      "    allianz       0.95      1.00      0.97        19\n",
      "     amazon       1.00      1.00      1.00        27\n",
      "  citigroup       1.00      1.00      1.00        21\n",
      "    fujitsu       0.95      1.00      0.97        19\n",
      "     garmin       1.00      0.94      0.97        17\n",
      "     github       1.00      1.00      1.00        17\n",
      "        ibm       1.00      1.00      1.00        19\n",
      "    metlife       0.94      0.94      0.94        18\n",
      "       uber       1.00      1.00      1.00        14\n",
      "      yahoo       1.00      1.00      1.00        14\n",
      "     zurich       1.00      0.94      0.97        16\n",
      "\n",
      "avg / total       0.99      0.99      0.99       215\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "accuweather       1.00      1.00      1.00         6\n",
      "    allianz       0.67      0.50      0.57         4\n",
      "     amazon       0.33      1.00      0.50         1\n",
      "  citigroup       0.25      0.50      0.33         2\n",
      "    fujitsu       1.00      0.50      0.67         2\n",
      "     garmin       1.00      0.33      0.50         3\n",
      "     github       1.00      1.00      1.00         3\n",
      "        ibm       0.50      1.00      0.67         1\n",
      "    metlife       0.50      0.50      0.50         2\n",
      "       uber       1.00      0.83      0.91         6\n",
      "      yahoo       1.00      1.00      1.00         5\n",
      "     zurich       1.00      1.00      1.00         3\n",
      "\n",
      "avg / total       0.87      0.79      0.80        38\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "accuweather       0.00      0.00      0.00        14\n",
      "    allianz       0.00      0.00      0.00        19\n",
      "     amazon       0.15      1.00      0.26        27\n",
      "  citigroup       0.00      0.00      0.00        21\n",
      "    fujitsu       1.00      0.42      0.59        19\n",
      "     garmin       0.00      0.00      0.00        17\n",
      "     github       0.00      0.00      0.00        17\n",
      "        ibm       0.00      0.00      0.00        19\n",
      "    metlife       0.42      0.56      0.48        18\n",
      "       uber       0.00      0.00      0.00        14\n",
      "      yahoo       0.00      0.00      0.00        14\n",
      "     zurich       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.14      0.21      0.12       215\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "accuweather       0.00      0.00      0.00         6\n",
      "    allianz       0.00      0.00      0.00         4\n",
      "     amazon       0.03      1.00      0.06         1\n",
      "  citigroup       0.00      0.00      0.00         2\n",
      "    fujitsu       0.00      0.00      0.00         2\n",
      "     garmin       0.00      0.00      0.00         3\n",
      "     github       0.00      0.00      0.00         3\n",
      "        ibm       0.00      0.00      0.00         1\n",
      "    metlife       0.00      0.00      0.00         2\n",
      "       uber       0.00      0.00      0.00         6\n",
      "      yahoo       0.00      0.00      0.00         5\n",
      "     zurich       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.00      0.03      0.00        38\n",
      "\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "accuweather       1.00      1.00      1.00        14\n",
      "    allianz       0.95      1.00      0.97        19\n",
      "     amazon       1.00      1.00      1.00        27\n",
      "  citigroup       1.00      1.00      1.00        21\n",
      "    fujitsu       1.00      1.00      1.00        19\n",
      "     garmin       1.00      1.00      1.00        17\n",
      "     github       1.00      1.00      1.00        17\n",
      "        ibm       1.00      1.00      1.00        19\n",
      "    metlife       1.00      0.94      0.97        18\n",
      "       uber       1.00      1.00      1.00        14\n",
      "      yahoo       1.00      1.00      1.00        14\n",
      "     zurich       1.00      1.00      1.00        16\n",
      "\n",
      "avg / total       1.00      1.00      1.00       215\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "accuweather       0.86      1.00      0.92         6\n",
      "    allianz       1.00      0.50      0.67         4\n",
      "     amazon       0.17      1.00      0.29         1\n",
      "  citigroup       0.33      0.50      0.40         2\n",
      "    fujitsu       0.00      0.00      0.00         2\n",
      "     garmin       0.67      0.67      0.67         3\n",
      "     github       1.00      1.00      1.00         3\n",
      "        ibm       0.33      1.00      0.50         1\n",
      "    metlife       0.50      0.50      0.50         2\n",
      "       uber       1.00      0.50      0.67         6\n",
      "      yahoo       1.00      0.80      0.89         5\n",
      "     zurich       0.50      0.33      0.40         3\n",
      "\n",
      "avg / total       0.76      0.66      0.67        38\n",
      "\n",
      "<class 'sklearn.svm.classes.LinearSVC'>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "accuweather       1.00      1.00      1.00        14\n",
      "    allianz       1.00      1.00      1.00        19\n",
      "     amazon       1.00      1.00      1.00        27\n",
      "  citigroup       1.00      1.00      1.00        21\n",
      "    fujitsu       1.00      1.00      1.00        19\n",
      "     garmin       1.00      1.00      1.00        17\n",
      "     github       1.00      1.00      1.00        17\n",
      "        ibm       1.00      1.00      1.00        19\n",
      "    metlife       1.00      1.00      1.00        18\n",
      "       uber       1.00      1.00      1.00        14\n",
      "      yahoo       1.00      1.00      1.00        14\n",
      "     zurich       1.00      1.00      1.00        16\n",
      "\n",
      "avg / total       1.00      1.00      1.00       215\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "accuweather       1.00      1.00      1.00         6\n",
      "    allianz       0.75      0.75      0.75         4\n",
      "     amazon       0.20      1.00      0.33         1\n",
      "  citigroup       0.25      0.50      0.33         2\n",
      "    fujitsu       0.00      0.00      0.00         2\n",
      "     garmin       0.50      0.67      0.57         3\n",
      "     github       1.00      0.67      0.80         3\n",
      "        ibm       0.00      0.00      0.00         1\n",
      "    metlife       0.50      0.50      0.50         2\n",
      "       uber       0.75      0.50      0.60         6\n",
      "      yahoo       1.00      0.80      0.89         5\n",
      "     zurich       0.50      0.33      0.40         3\n",
      "\n",
      "avg / total       0.69      0.63      0.64        38\n",
      "\n",
      "<class 'sklearn.svm.classes.SVC'>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "accuweather       0.00      0.00      0.00        14\n",
      "    allianz       0.00      0.00      0.00        19\n",
      "     amazon       0.13      1.00      0.22        27\n",
      "  citigroup       0.00      0.00      0.00        21\n",
      "    fujitsu       0.00      0.00      0.00        19\n",
      "     garmin       0.00      0.00      0.00        17\n",
      "     github       0.00      0.00      0.00        17\n",
      "        ibm       0.00      0.00      0.00        19\n",
      "    metlife       0.00      0.00      0.00        18\n",
      "       uber       0.00      0.00      0.00        14\n",
      "      yahoo       0.00      0.00      0.00        14\n",
      "     zurich       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.02      0.13      0.03       215\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "accuweather       0.00      0.00      0.00         6\n",
      "    allianz       0.00      0.00      0.00         4\n",
      "     amazon       0.03      1.00      0.05         1\n",
      "  citigroup       0.00      0.00      0.00         2\n",
      "    fujitsu       0.00      0.00      0.00         2\n",
      "     garmin       0.00      0.00      0.00         3\n",
      "     github       0.00      0.00      0.00         3\n",
      "        ibm       0.00      0.00      0.00         1\n",
      "    metlife       0.00      0.00      0.00         2\n",
      "       uber       0.00      0.00      0.00         6\n",
      "      yahoo       0.00      0.00      0.00         5\n",
      "     zurich       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.00      0.03      0.00        38\n",
      "\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "accuweather       1.00      1.00      1.00        14\n",
      "    allianz       1.00      1.00      1.00        19\n",
      "     amazon       1.00      1.00      1.00        27\n",
      "  citigroup       1.00      1.00      1.00        21\n",
      "    fujitsu       1.00      1.00      1.00        19\n",
      "     garmin       1.00      1.00      1.00        17\n",
      "     github       1.00      1.00      1.00        17\n",
      "        ibm       1.00      1.00      1.00        19\n",
      "    metlife       1.00      1.00      1.00        18\n",
      "       uber       1.00      1.00      1.00        14\n",
      "      yahoo       1.00      1.00      1.00        14\n",
      "     zurich       1.00      1.00      1.00        16\n",
      "\n",
      "avg / total       1.00      1.00      1.00       215\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "accuweather       1.00      0.83      0.91         6\n",
      "    allianz       0.30      0.75      0.43         4\n",
      "     amazon       0.50      1.00      0.67         1\n",
      "  citigroup       0.33      0.50      0.40         2\n",
      "    fujitsu       0.50      0.50      0.50         2\n",
      "     garmin       1.00      0.67      0.80         3\n",
      "     github       0.67      0.67      0.67         3\n",
      "        ibm       0.00      0.00      0.00         1\n",
      "    metlife       1.00      0.50      0.67         2\n",
      "       uber       0.75      0.50      0.60         6\n",
      "      yahoo       1.00      0.40      0.57         5\n",
      "     zurich       0.50      0.33      0.40         3\n",
      "\n",
      "avg / total       0.72      0.58      0.61        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(binary=True)\n",
    "\n",
    "for clf in clfs:\n",
    "    print(str(clf.__class__))\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('clf', clf),\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = pipeline.predict(X_train)\n",
    "    print(metrics.classification_report(y_train, y_pred, target_names=['accuweather',\n",
    "                                                                       'allianz',\n",
    "                                                                       'amazon',\n",
    "                                                                       'citigroup',\n",
    "                                                                       'fujitsu',\n",
    "                                                                       'garmin',\n",
    "                                                                       'github',\n",
    "                                                                       'ibm',\n",
    "                                                                       'metlife',\n",
    "                                                                       'uber',\n",
    "                                                                       'yahoo',\n",
    "                                                                       'zurich']))\n",
    "\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(metrics.classification_report(y_test, y_pred, target_names=['accuweather',\n",
    "                                                                       'allianz',\n",
    "                                                                       'amazon',\n",
    "                                                                       'citigroup',\n",
    "                                                                       'fujitsu',\n",
    "                                                                       'garmin',\n",
    "                                                                       'github',\n",
    "                                                                       'ibm',\n",
    "                                                                       'metlife',\n",
    "                                                                       'uber',\n",
    "                                                                       'yahoo',\n",
    "                                                                       'zurich']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cómo se puede ver en el análisis anterior el modelo que mejor clasifico los datos fue LinearSVC. Por lo que se proseguirá con ese y se harán las optimizaciones finales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "accuweather       1.00      1.00      1.00        14\n",
      "    allianz       1.00      1.00      1.00        19\n",
      "     amazon       1.00      1.00      1.00        27\n",
      "  citigroup       1.00      1.00      1.00        21\n",
      "    fujitsu       1.00      1.00      1.00        19\n",
      "     garmin       1.00      1.00      1.00        17\n",
      "     github       1.00      1.00      1.00        17\n",
      "        ibm       1.00      1.00      1.00        19\n",
      "    metlife       1.00      1.00      1.00        18\n",
      "       uber       1.00      1.00      1.00        14\n",
      "      yahoo       1.00      1.00      1.00        14\n",
      "     zurich       1.00      1.00      1.00        16\n",
      "\n",
      "avg / total       1.00      1.00      1.00       215\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "accuweather       1.00      1.00      1.00         6\n",
      "    allianz       0.75      0.75      0.75         4\n",
      "     amazon       0.20      1.00      0.33         1\n",
      "  citigroup       0.25      0.50      0.33         2\n",
      "    fujitsu       0.00      0.00      0.00         2\n",
      "     garmin       0.50      0.67      0.57         3\n",
      "     github       1.00      0.67      0.80         3\n",
      "        ibm       0.00      0.00      0.00         1\n",
      "    metlife       0.50      0.50      0.50         2\n",
      "       uber       0.75      0.50      0.60         6\n",
      "      yahoo       1.00      0.80      0.89         5\n",
      "     zurich       0.50      0.33      0.40         3\n",
      "\n",
      "avg / total       0.69      0.63      0.64        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(binary=True)),\n",
    "    ('clf', LinearSVC(random_state=0)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_train)\n",
    "print(metrics.classification_report(y_train, y_pred, target_names=['accuweather',\n",
    "                                                                       'allianz',\n",
    "                                                                       'amazon',\n",
    "                                                                       'citigroup',\n",
    "                                                                       'fujitsu',\n",
    "                                                                       'garmin',\n",
    "                                                                       'github',\n",
    "                                                                       'ibm',\n",
    "                                                                       'metlife',\n",
    "                                                                       'uber',\n",
    "                                                                       'yahoo',\n",
    "                                                                       'zurich']))\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=['accuweather',\n",
    "                                                                   'allianz',\n",
    "                                                                   'amazon',\n",
    "                                                                   'citigroup',\n",
    "                                                                   'fujitsu',\n",
    "                                                                   'garmin',\n",
    "                                                                   'github',\n",
    "                                                                   'ibm',\n",
    "                                                                   'metlife',\n",
    "                                                                   'uber',\n",
    "                                                                   'yahoo',\n",
    "                                                                   'zurich']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uber'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = 'everyones private driver'\n",
    "dataset['target_names'][int(pipeline.predict([description]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de hacer algunas pruebas, se procede a optimizar el modelo elejido buscando subir un poco los resultados en test y mejorar la precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[                                                                        ]   1%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'vect__binary': [True],\n",
    "    'vect__lowercase': [True],\n",
    "    'vect__sublinear_tf': [True, False],\n",
    "    'vect__ngram_range': [(1, 3), (1, 4),(1, 7)],\n",
    "    'vect__strip_accents': ['ascii'],\n",
    "    'vect__analyzer': ['word'],\n",
    "    'vect__min_df': [1, 2, 3],\n",
    "    'vect__max_df': [1.],\n",
    "    'clf__multi_class' : ['ovr', 'crammer_singer'],\n",
    "    'clf__random_state': [0],\n",
    "    'clf__fit_intercept':[True, False],\n",
    "    'clf__loss':['hinge', 'squared_hinge'],\n",
    "    'clf__C':[1.0, 0.1],\n",
    "}\n",
    "\n",
    "params_list = list(ParameterGrid(param_grid))\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "results = []\n",
    "print(len(params_list))\n",
    "\n",
    "bar = progressbar.ProgressBar(maxval=len(params_list), \n",
    "                              widgets=[progressbar.Bar('=', '[', ']'), ' ', \n",
    "                                       progressbar.Percentage()])\n",
    "bar.start()\n",
    "\n",
    "\n",
    "i = 0\n",
    "barra = ''\n",
    "for params in params_list:\n",
    "    bar.update(i+1)\n",
    "    pipeline.set_params(**params)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "    result = {'acc': acc, 'f1': f1}\n",
    "        \n",
    "    results.append({\n",
    "        **result,\n",
    "        **params,\n",
    "    })\n",
    "    i += 1\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>clf__C</th>\n",
       "      <th>clf__fit_intercept</th>\n",
       "      <th>clf__loss</th>\n",
       "      <th>clf__multi_class</th>\n",
       "      <th>clf__random_state</th>\n",
       "      <th>f1</th>\n",
       "      <th>vect__analyzer</th>\n",
       "      <th>vect__binary</th>\n",
       "      <th>vect__lowercase</th>\n",
       "      <th>vect__max_df</th>\n",
       "      <th>vect__min_df</th>\n",
       "      <th>vect__ngram_range</th>\n",
       "      <th>vect__strip_accents</th>\n",
       "      <th>vect__sublinear_tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>hinge</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0</td>\n",
       "      <td>0.825498</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>hinge</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0</td>\n",
       "      <td>0.825498</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>hinge</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0</td>\n",
       "      <td>0.825498</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>hinge</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0</td>\n",
       "      <td>0.825498</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>hinge</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0</td>\n",
       "      <td>0.803276</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 7)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>hinge</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0</td>\n",
       "      <td>0.803276</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 7)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>hinge</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.803276</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>hinge</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.803276</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>hinge</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.803276</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>hinge</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.803276</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          acc  clf__C  clf__fit_intercept clf__loss clf__multi_class  \\\n",
       "216  0.842105     0.1               False     hinge              ovr   \n",
       "217  0.842105     0.1               False     hinge              ovr   \n",
       "218  0.842105     0.1               False     hinge              ovr   \n",
       "219  0.842105     0.1               False     hinge              ovr   \n",
       "220  0.842105     0.1               False     hinge              ovr   \n",
       "221  0.842105     0.1               False     hinge              ovr   \n",
       "234  0.842105     0.1               False     hinge   crammer_singer   \n",
       "235  0.842105     0.1               False     hinge   crammer_singer   \n",
       "236  0.842105     0.1               False     hinge   crammer_singer   \n",
       "237  0.842105     0.1               False     hinge   crammer_singer   \n",
       "\n",
       "     clf__random_state        f1 vect__analyzer  vect__binary  \\\n",
       "216                  0  0.825498           word          True   \n",
       "217                  0  0.825498           word          True   \n",
       "218                  0  0.825498           word          True   \n",
       "219                  0  0.825498           word          True   \n",
       "220                  0  0.803276           word          True   \n",
       "221                  0  0.803276           word          True   \n",
       "234                  0  0.803276           word          True   \n",
       "235                  0  0.803276           word          True   \n",
       "236                  0  0.803276           word          True   \n",
       "237                  0  0.803276           word          True   \n",
       "\n",
       "     vect__lowercase  vect__max_df  vect__min_df vect__ngram_range  \\\n",
       "216             True           1.0             1            (1, 3)   \n",
       "217             True           1.0             1            (1, 3)   \n",
       "218             True           1.0             1            (1, 4)   \n",
       "219             True           1.0             1            (1, 4)   \n",
       "220             True           1.0             1            (1, 7)   \n",
       "221             True           1.0             1            (1, 7)   \n",
       "234             True           1.0             1            (1, 3)   \n",
       "235             True           1.0             1            (1, 3)   \n",
       "236             True           1.0             1            (1, 4)   \n",
       "237             True           1.0             1            (1, 4)   \n",
       "\n",
       "    vect__strip_accents  vect__sublinear_tf  \n",
       "216               ascii                True  \n",
       "217               ascii               False  \n",
       "218               ascii                True  \n",
       "219               ascii               False  \n",
       "220               ascii                True  \n",
       "221               ascii               False  \n",
       "234               ascii                True  \n",
       "235               ascii               False  \n",
       "236               ascii                True  \n",
       "237               ascii               False  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(['acc', 'f1'], ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente nos quedamos con la configuración que mejor a dado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "accuweather       0.86      1.00      0.92         6\n",
      "    allianz       0.75      0.75      0.75         4\n",
      "     amazon       1.00      1.00      1.00         1\n",
      "  citigroup       0.25      0.50      0.33         2\n",
      "    fujitsu       1.00      0.50      0.67         2\n",
      "     garmin       1.00      0.67      0.80         3\n",
      "     github       1.00      1.00      1.00         3\n",
      "        ibm       1.00      1.00      1.00         1\n",
      "    metlife       1.00      0.50      0.67         2\n",
      "       uber       1.00      0.83      0.91         6\n",
      "      yahoo       1.00      1.00      1.00         5\n",
      "     zurich       0.75      1.00      0.86         3\n",
      "\n",
      "avg / total       0.89      0.84      0.85        38\n",
      "\n",
      "[[6 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 3 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 2 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 5 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 5 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(\n",
    "        binary=True,\n",
    "        lowercase=True,\n",
    "        strip_accents='ascii',\n",
    "        analyzer='word',\n",
    "        min_df=1,\n",
    "        max_df=1.,\n",
    "        ngram_range=(1, 3),\n",
    "    )),\n",
    "    ('clf', LinearSVC(C=0.1, loss='hinge', multi_class='ovr', penalty='l2', random_state=0, fit_intercept=False)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=['accuweather',\n",
    "                                                                   'allianz',\n",
    "                                                                   'amazon',\n",
    "                                                                   'citigroup',\n",
    "                                                                   'fujitsu',\n",
    "                                                                   'garmin',\n",
    "                                                                   'github',\n",
    "                                                                   'ibm',\n",
    "                                                                   'metlife',\n",
    "                                                                   'uber',\n",
    "                                                                   'yahoo',\n",
    "                                                                   'zurich']))\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[=                                                                       ]   1%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'vect__binary': [True],\n",
    "    'vect__lowercase': [True],\n",
    "    'vect__sublinear_tf': [True, False],\n",
    "    'vect__ngram_range': [(1, 3), (1, 4),(1, 7)],\n",
    "    'vect__strip_accents': ['ascii'],\n",
    "    'vect__analyzer': ['word'],\n",
    "    'vect__min_df': [1, 2, 3, 5, 6],\n",
    "    'vect__max_df': [1.],\n",
    "    'clf__multi_class' : ['ovr'],\n",
    "    'clf__random_state': [0],\n",
    "    'clf__fit_intercept':[True],\n",
    "    'clf__C':[1.0, 0.1, 100, 10],\n",
    "    'clf__n_jobs': [-1],\n",
    "}\n",
    "\n",
    "params_list = list(ParameterGrid(param_grid))\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "\n",
    "results = []\n",
    "print(len(params_list))\n",
    "\n",
    "bar = progressbar.ProgressBar(maxval=len(params_list), \n",
    "                              widgets=[progressbar.Bar('=', '[', ']'), ' ', \n",
    "                                       progressbar.Percentage()])\n",
    "bar.start()\n",
    "\n",
    "\n",
    "i = 0\n",
    "barra = ''\n",
    "for params in params_list:\n",
    "    bar.update(i+1)\n",
    "    pipeline.set_params(**params)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = pipeline.predict(X_train)\n",
    "    acc = metrics.accuracy_score(y_train, y_pred)\n",
    "    f1 = metrics.f1_score(y_train, y_pred, average='macro')\n",
    "    result = {'acc': acc, 'f1': f1}\n",
    "        \n",
    "    results.append({\n",
    "        **result,\n",
    "        **params,\n",
    "    })\n",
    "    i += 1\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>clf__C</th>\n",
       "      <th>clf__fit_intercept</th>\n",
       "      <th>clf__multi_class</th>\n",
       "      <th>clf__n_jobs</th>\n",
       "      <th>clf__random_state</th>\n",
       "      <th>f1</th>\n",
       "      <th>vect__analyzer</th>\n",
       "      <th>vect__binary</th>\n",
       "      <th>vect__lowercase</th>\n",
       "      <th>vect__max_df</th>\n",
       "      <th>vect__min_df</th>\n",
       "      <th>vect__ngram_range</th>\n",
       "      <th>vect__strip_accents</th>\n",
       "      <th>vect__sublinear_tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>ovr</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>ovr</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>ovr</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>ovr</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>ovr</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 7)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>ovr</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 7)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>True</td>\n",
       "      <td>ovr</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>True</td>\n",
       "      <td>ovr</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>True</td>\n",
       "      <td>ovr</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>True</td>\n",
       "      <td>ovr</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    acc  clf__C  clf__fit_intercept clf__multi_class  clf__n_jobs  \\\n",
       "0   1.0     1.0                True              ovr           -1   \n",
       "1   1.0     1.0                True              ovr           -1   \n",
       "2   1.0     1.0                True              ovr           -1   \n",
       "3   1.0     1.0                True              ovr           -1   \n",
       "4   1.0     1.0                True              ovr           -1   \n",
       "5   1.0     1.0                True              ovr           -1   \n",
       "60  1.0   100.0                True              ovr           -1   \n",
       "61  1.0   100.0                True              ovr           -1   \n",
       "62  1.0   100.0                True              ovr           -1   \n",
       "63  1.0   100.0                True              ovr           -1   \n",
       "\n",
       "    clf__random_state   f1 vect__analyzer  vect__binary  vect__lowercase  \\\n",
       "0                   0  1.0           word          True             True   \n",
       "1                   0  1.0           word          True             True   \n",
       "2                   0  1.0           word          True             True   \n",
       "3                   0  1.0           word          True             True   \n",
       "4                   0  1.0           word          True             True   \n",
       "5                   0  1.0           word          True             True   \n",
       "60                  0  1.0           word          True             True   \n",
       "61                  0  1.0           word          True             True   \n",
       "62                  0  1.0           word          True             True   \n",
       "63                  0  1.0           word          True             True   \n",
       "\n",
       "    vect__max_df  vect__min_df vect__ngram_range vect__strip_accents  \\\n",
       "0            1.0             1            (1, 3)               ascii   \n",
       "1            1.0             1            (1, 3)               ascii   \n",
       "2            1.0             1            (1, 4)               ascii   \n",
       "3            1.0             1            (1, 4)               ascii   \n",
       "4            1.0             1            (1, 7)               ascii   \n",
       "5            1.0             1            (1, 7)               ascii   \n",
       "60           1.0             1            (1, 3)               ascii   \n",
       "61           1.0             1            (1, 3)               ascii   \n",
       "62           1.0             1            (1, 4)               ascii   \n",
       "63           1.0             1            (1, 4)               ascii   \n",
       "\n",
       "    vect__sublinear_tf  \n",
       "0                 True  \n",
       "1                False  \n",
       "2                 True  \n",
       "3                False  \n",
       "4                 True  \n",
       "5                False  \n",
       "60                True  \n",
       "61               False  \n",
       "62                True  \n",
       "63               False  "
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(['acc', 'f1'], ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "accuweather       1.00      1.00      1.00        20\n",
      "    allianz       1.00      1.00      1.00        23\n",
      "     amazon       1.00      1.00      1.00        28\n",
      "  citigroup       1.00      1.00      1.00        23\n",
      "    fujitsu       1.00      1.00      1.00        21\n",
      "     garmin       1.00      1.00      1.00        20\n",
      "     github       1.00      1.00      1.00        20\n",
      "        ibm       1.00      1.00      1.00        20\n",
      "    metlife       1.00      1.00      1.00        20\n",
      "       uber       1.00      1.00      1.00        19\n",
      "      yahoo       1.00      1.00      1.00        19\n",
      "     zurich       1.00      1.00      1.00        19\n",
      "\n",
      "avg / total       1.00      1.00      1.00       252\n",
      "\n",
      "[[20  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 23  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 28  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 23  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 21  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 20  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 20  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 20  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 20  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 19  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 19  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 19]]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(\n",
    "        binary=True,\n",
    "        strip_accents='ascii',\n",
    "        analyzer='word',\n",
    "        min_df=1,\n",
    "        max_df=1.,\n",
    "        ngram_range=(1, 3),\n",
    "    )),\n",
    "    ('clf', LogisticRegression(C=1.0, multi_class='ovr', penalty='l2', random_state=0, fit_intercept=True)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_train)\n",
    "print(metrics.classification_report(y_train, y_pred, target_names=['accuweather',\n",
    "                                                                   'allianz',\n",
    "                                                                   'amazon',\n",
    "                                                                   'citigroup',\n",
    "                                                                   'fujitsu',\n",
    "                                                                   'garmin',\n",
    "                                                                   'github',\n",
    "                                                                   'ibm',\n",
    "                                                                   'metlife',\n",
    "                                                                   'uber',\n",
    "                                                                   'yahoo',\n",
    "                                                                   'zurich']))\n",
    "cm = metrics.confusion_matrix(y_train, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'github'"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = 'repositories'\n",
    "dataset['target_names'][int(pipeline.predict([description]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_array = pipeline.predict_proba([description])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 2, 3])"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pred = pred_array.argsort()[-3:][::-1]\n",
    "best_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "github   0.2559808449419713\n",
      "amazon   0.08370827219471051\n",
      "citigroup   0.07122536590251825\n"
     ]
    }
   ],
   "source": [
    "for pred in best_pred:\n",
    "    #print(pred)\n",
    "    print(str(dataset['target_names'][pred]) + \"   \" + str(pred_array[pred]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'company_clasifier_final_model'\n",
    "f = open(filename, 'wb')\n",
    "pickle.dump(pipeline, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
